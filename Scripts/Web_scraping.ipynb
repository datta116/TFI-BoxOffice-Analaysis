{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615b9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7981a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Salaar Box Office Collection | Day Wise | Worldwide\n",
      "\n",
      "salaar.csv\n",
      "                    day                                          india_net  \\\n",
      "0    Day 1 [1st Friday]  ₹ 90.7 Cr [Te: 66.75 Cr ; Mal: 3.55 Cr; Ta: 3....   \n",
      "1  Day 2 [1st Saturday]  ₹ 56.35 Cr [Te: 34.25 Cr ; Mal: 1.75 Cr; Ta: 3...   \n",
      "2    Day 3 [1st Sunday]  ₹ 62.05 Cr [Te: 35 Cr ; Mal: 1.55 Cr; Ta: 3.2 ...   \n",
      "3    Day 4 [1st Monday]  ₹ 46.3 Cr [Te: 27.1 Cr ; Mal: 1.3 Cr; Ta: 2.05...   \n",
      "4   Day 5 [1st Tuesday]  ₹ 24.9 Cr [Te: 13.7 Cr ; Mal: 0.7 Cr; Ta: 1.1 ...   \n",
      "\n",
      "  worldwide                                              movie  \n",
      "0         -  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "1   -37.87%  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "2    10.12%  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "3   -25.38%  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "4   -46.22%  Salaar Box Office Collection | Day Wise | Worl...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scrape_sacnilk(url):\n",
    "    # Get page\n",
    "    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # ---------- MOVIE NAME ----------\n",
    "    try:\n",
    "        movie_name = soup.find(\"h1\").text.strip()\n",
    "    except:\n",
    "        movie_name = \"Unknown Movie\"\n",
    "\n",
    "    print(f\"Scraping: {movie_name}\")\n",
    "\n",
    "    # ---------- DAY-WISE COLLECTION TABLE ----------\n",
    "    day_data = []\n",
    "\n",
    "    day_table = soup.find(\"table\")\n",
    "    if day_table:\n",
    "        for tr in day_table.find_all(\"tr\")[1:]:\n",
    "            cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "            if len(cols) >= 3:\n",
    "                day_data.append({\n",
    "                    \"day\": cols[0],\n",
    "                    \"india_net\": cols[1],\n",
    "                    \"worldwide\": cols[2]\n",
    "                })\n",
    "\n",
    "    # ---------- STATE-WISE COLLECTION ----------\n",
    "    state_data = {}\n",
    "    state_table = soup.find_all(\"table\")\n",
    "    if len(state_table) > 1:   # second table = state wise\n",
    "        rows = state_table[1].find_all(\"tr\")\n",
    "        for tr in rows[1:]:\n",
    "            cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "            if len(cols) == 2:\n",
    "                state = cols[0]\n",
    "                gross = cols[1]\n",
    "                state_data[state] = gross\n",
    "\n",
    "    # ---------- CREATE DATAFRAME ----------\n",
    "    df_daywise = pd.DataFrame(day_data)\n",
    "\n",
    "    # Add movie name to all rows\n",
    "    df_daywise[\"movie\"] = movie_name\n",
    "\n",
    "    # Add state-wise data as separate columns\n",
    "    for state, gross in state_data.items():\n",
    "        df_daywise[f\"state_{state}\"] = gross\n",
    "\n",
    "    return df_daywise\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# RUN SCRAPER ON YOUR MOVIE PAGE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "url = \"https://www.sacnilk.com/news/_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "\n",
    "df = scrape_sacnilk(url)\n",
    "\n",
    "df.to_csv(\"movie_collection.csv\", index=False)\n",
    "\n",
    "print(\"\\nsalaar.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f6388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Salaar Box Office Collection | Day Wise | Worldwide\n",
      "\n",
      "Day-wise Collection:\n",
      "['Day 1 [1st Friday]', '₹ 90.7 Cr [Te: 66.75 Cr ; Mal: 3.55 Cr; Ta: 3.75 Cr; Ka: 0.9 Cr; Hi: 15.75 Cr]', '-']\n",
      "['Day 2 [1st Saturday]', '₹ 56.35 Cr [Te: 34.25 Cr ; Mal: 1.75 Cr; Ta: 3.05 Cr; Ka: 0.95 Cr; Hi: 16.35 Cr]', '-37.87%']\n",
      "['Day 3 [1st Sunday]', '₹ 62.05 Cr [Te: 35 Cr ; Mal: 1.55 Cr; Ta: 3.2 Cr; Ka: 1.2 Cr; Hi: 21.1 Cr]', '10.12%']\n",
      "['Day 4 [1st Monday]', '₹ 46.3 Cr [Te: 27.1 Cr ; Mal: 1.3 Cr; Ta: 2.05 Cr; Ka: 0.85 Cr; Hi: 15 Cr]', '-25.38%']\n",
      "['Day 5 [1st Tuesday]', '₹ 24.9 Cr [Te: 13.7 Cr ; Mal: 0.7 Cr; Ta: 1.1 Cr; Ka: 0.3 Cr; Hi: 9.1 Cr]', '-46.22%']\n",
      "['Day 6 [1st Wednesday]', '₹ 15.6 Cr [Te: 5.75 Cr ; Mal: 0.5 Cr; Ta: 1.1 Cr; Ka: 0.25 Cr; Hi: 8 Cr]', '-37.35%']\n",
      "['Day 7 [1st Thursday]', '₹ 12.1 Cr [Te: 3.5 Cr ; Mal: 0.3 Cr; Ta: 0.95 Cr; Ka: 0.15 Cr; Hi: 7.2 Cr]', '-22.44%']\n",
      "['Week 1 Collection', '₹ 308 Cr [Te: 186.05 Cr ; Mal: 9.65; Ta: 15.2; Ka: 4.6; Hi: 92.5]', '-']\n",
      "['Day 8 [2nd Friday]', '₹ 9.62 Cr [Te: 2.95 Cr ; Mal: 0.2 Cr; Ta: 0.4 Cr; Ka: 0.07 Cr; Hi: 6 Cr]', '-20.50%']\n",
      "['Day 9 [2nd Saturday]', '₹ 12.55 Cr [Te: 4.5 Cr ; Mal: 0.22 Cr; Ta: 0.45 Cr; Ka: 0.13 Cr; Hi: 7.25 Cr]', '30.46%']\n",
      "['Day 10 [2nd Sunday]', '₹ 15.1 Cr [Te: 4.75 Cr ; Mal: 0.22 Cr; Ta: 0.5 Cr; Ka: 0.13 Cr; Hi: 9.5 Cr]', '20.32%']\n",
      "['Day 11 [2nd Monday]', '₹ 16.6 Cr [Te: 7.5 Cr ; Mal: 0.18 Cr; Ta: 0.55 Cr; Ka: 0.12 Cr; Hi: 8.25 Cr]', '9.93%']\n",
      "['Day 12 [2nd Tuesday]', '₹ 6.45 Cr [Te: 2 Cr ; Mal: 0.12 Cr; Ta: 0.3 Cr; Ka: 0.03 Cr; Hi: 4 Cr]', '-61.14%']\n",
      "['Day 13 [2nd Wednesday]', '₹ 5.18 Cr [Te: 1.5 Cr ; Mal: 0.1 Cr; Ta: 0.3 Cr; Ka: 0.03 Cr; Hi: 3.25 Cr]', '-19.69%']\n",
      "['Day 14 [2nd Thursday]', '₹ 4.6 Cr [Te: 1.25 Cr ; Mal: 0.07 Cr; Ta: 0.25 Cr; Ka: 0.03 Cr; Hi: 3 Cr]', '-11.20%']\n",
      "['Week 2 Collection', '₹ 70.1 Cr [Te: 24.45 Cr ; Mal: 1.11; Ta: 2.75; Ka: 0.54; Hi: 41.25]', '-77.24%']\n",
      "['Day 15 [3rd Friday]', '₹ 3.65 Cr [Te: 0.95 Cr ; Mal: 0.03 Cr; Ta: 0.14 Cr; Ka: 0.03 Cr; Hi: 2.5 Cr]', '-20.65%']\n",
      "['Day 16 [3rd Saturday]', '₹ 5.45 Cr [Te: 1.4 Cr ; Mal: 0.05 Cr; Ta: 0.2 Cr; Ka: 0.05 Cr; Hi: 3.75 Cr]', '49.32%']\n",
      "['Day 17 [3rd Sunday]', '₹ 6.05 Cr [Te: 1.5 Cr ; Mal: 0.08 Cr; Ta: 0.25 Cr; Ka: 0.07 Cr; Hi: 4.15 Cr]', '11.01%']\n",
      "['Day 18 [3rd Monday]', '₹ 2.4 Cr [Te: 0.7 Cr ; Mal: 0.03 Cr; Ta: 0.14 Cr; Ka: 0.03 Cr; Hi: 1.5 Cr]', '-60.33%']\n",
      "['Day 19 [3rd Tuesday]', '₹ 2.2 Cr [Te: 0.65 Cr ; Mal: 0.04 Cr; Ta: 0.13 Cr; Ka: 0.03 Cr; Hi: 1.35 Cr]', '-8.33%']\n",
      "['Day 20 [3rd Wednesday]', '₹ 2 Cr [Te: 0.55 Cr ; Mal: 0.04 Cr; Ta: 0.14 Cr; Ka: 0.02 Cr; Hi: 1.25 Cr]', '-9.09%']\n",
      "['Day 21 [3rd Thursday]', '₹ 1.95 Cr [Te: 0.6 Cr ; Mal: 0.01 Cr; Ta: 0.13 Cr; Ka: 0.01 Cr; Hi: 1.2 Cr]', '-2.50%']\n",
      "['Week 3 Collection', '₹ 23.7 Cr [Te: 6.35 Cr ; Mal: 0.28; Ta: 1.13; Ka: 0.24; Hi: 15.7]', '-66.19%']\n",
      "['Day 22 [4th Friday]', '₹ 0.5 Cr [Te: 0.15 Cr ; Hi: 0.35 Cr]', '-74.36%']\n",
      "['Day 23 [4th Saturday]', '₹ 0.65 Cr [Te: 0.2 Cr ; Hi: 0.45 Cr]', '30.00%']\n",
      "['Day 24 [4th Sunday]', '₹ 0.95 Cr [Te: 0.25 Cr ; Hi: 0.7 Cr]', '46.15%']\n",
      "['Day 25 [4th Monday]', '₹ 0.55 Cr [Te: 0.2 Cr ; Hi: 0.35 Cr]', '-42.11%']\n",
      "['Day 26 [4th Tuesday]', '₹ 0.36 Cr [Te: 0.13 Cr ; Hi: 0.23 Cr]', '-34.55%']\n",
      "['Day 27 [4th Wednesday]', '₹ 0.32 Cr [Te: 0.1 Cr ; Hi: 0.22 Cr]', '-11.11%']\n",
      "['Day 28 [4th Thursday]', '₹ 0.27 Cr [Te: 0.07 Cr ; Hi: 0.2 Cr]', '-15.63%']\n",
      "['Week 4 Collection', '₹ 3.6 Cr [Te: 1.1 Cr ; Mal: 0; Ta: 0; Ka: 0; Hi: 2.5]', '-84.81%']\n",
      "['Day 29 [5th Friday]', '₹ 0.12 Cr [Te: 0.05 Cr ; Hi: 0.07 Cr]', '-55.56%']\n",
      "['Day 30 [5th Saturday]', '₹ 0.15 Cr [Te: 0.05 Cr ; Hi: 0.1 Cr]', '25.00%']\n",
      "['Day 31 [5th Sunday]', '₹ 0.19 Cr [Te: 0.04 Cr ; Hi: 0.15 Cr]', '26.67%']\n",
      "['Day 32 [5th Monday]', '₹ 0.15 Cr [Te: 0.05 Cr ; Hi: 0.1 Cr]', '-21.05%']\n",
      "['Day 33 [5th Tuesday]', '₹ 0.15 Cr [Te: 0.05 Cr ; Hi: 0.1 Cr]', '0.00%']\n",
      "['Day 34 [5th Wednesday]', '₹ 0.14 Cr [Te: 0.04 Cr ; Hi: 0.1 Cr]', '-6.67%']\n",
      "['Day 35 [5th Thursday]', '₹ 0.05 Cr [Te: 0.02 Cr ; Hi: 0.03 Cr]', '-64.29%']\n",
      "['Week 5 Collection', '₹ 0.95 Cr [Te: 0.3 Cr ; Mal: 0; Ta: 0; Ka: 0; Hi: 0.65]', '-73.61%']\n",
      "['Week 6 Collection', '₹ 0.1 Cr [Te: 0.05 Cr ; Mal: 0; Ta: 0; Ka: 0; Hi: 0.05]', '-89.47%']\n",
      "['Total', '₹ 406.45 Cr [Te: 218.3 Cr ; Mal: 11.04 Cr; Ta: 19.08 Cr; Ka: 5.38 Cr; Hi: 152.65 Cr]', '-']\n",
      "\n",
      "State-wise Collection:\n",
      "['Day 1 [1st Friday]', '₹ 11.65 Cr', '₹ 67.1 Cr', '₹ 4.9 Cr', '₹ 4.65 Cr', '₹ 18.8 Cr', '₹ 107.1 Cr']\n",
      "['Day 2 [1st Saturday]', '₹ 7.25 Cr', '₹ 33.5 Cr', '₹ 4 Cr', '₹ 2.65 Cr', '₹ 19.3 Cr', '₹ 66.7 Cr']\n",
      "['Day 3 [1st Sunday]', '₹ 6.7 Cr', '₹ 35.6 Cr', '₹ 4.1 Cr', '₹ 2.3 Cr', '₹ 24.8 Cr', '₹ 73.5 Cr']\n",
      "['Day 4 [1st Monday]', '₹ 4.65 Cr', '₹ 28.4 Cr', '₹ 2.7 Cr', '₹ 1.8 Cr', '₹ 16.65 Cr', '₹ 54.2 Cr']\n",
      "['Day 5 [1st Tuesday]', '₹ 2.2 Cr', '₹ 16.2 Cr', '₹ 1.1 Cr', '₹ 1.05 Cr', '₹ 8.85 Cr', '₹ 29.4 Cr']\n",
      "['Day 6 [1st Wednesday]', '₹ 1.3 Cr', '₹ 7.1 Cr', '₹ 1.05 Cr', '₹ 0.8 Cr', '₹ 8.05 Cr', '₹ 18.3 Cr']\n",
      "['Day 7 [1st Thursday]', '₹ 1.2 Cr', '₹ 4 Cr', '₹ 0.95 Cr', '₹ 0.65 Cr', '₹ 7.5 Cr', '₹ 14.3 Cr']\n",
      "['Week 1 Gross', '₹ 34.95 Cr', '₹ 191.9 Cr', '₹ 18.8 Cr', '₹ 13.9 Cr', '₹ 103.95 Cr', '₹ 363.5 Cr']\n",
      "['Day 8 [2nd Friday]', '₹ 0.75 Cr', '₹ 2.9 Cr', '₹ 0.5 Cr', '₹ 0.45 Cr', '₹ 6.75 Cr', '₹ 11.35 Cr']\n",
      "['Day 9 [2nd Saturday]', '₹ 1.1 Cr', '₹ 4.75 Cr', '₹ 0.65 Cr', '₹ 0.5 Cr', '₹ 7.75 Cr', '₹ 14.75 Cr']\n",
      "['Day 10 [2nd Sunday]', '₹ 1.2 Cr', '₹ 5 Cr', '₹ 0.8 Cr', '₹ 0.5 Cr', '₹ 10.3 Cr', '₹ 17.8 Cr']\n",
      "['Day 11 [2nd Monday]', '₹ 1.1 Cr', '₹ 7.9 Cr', '₹ 0.7 Cr', '₹ 0.4 Cr', '₹ 9.5 Cr', '₹ 19.6 Cr']\n",
      "['Day 12 [2nd Tuesday]', '₹ 0.5 Cr', '₹ 2.2 Cr', '₹ 0.5 Cr', '₹ 0.3 Cr', '₹ 4.5 Cr', '₹ 8 Cr']\n",
      "['Day 13 [2nd Wednesday]', '₹ 0.45 Cr', '₹ 1.35 Cr', '₹ 0.5 Cr', '₹ 0.25 Cr', '₹ 3.6 Cr', '₹ 6.15 Cr']\n",
      "['Day 14 [2nd Thursday]', '₹ 0.35 Cr', '₹ 1 Cr', '₹ 0.4 Cr', '₹ 0.2 Cr', '₹ 3.45 Cr', '₹ 5.4 Cr']\n",
      "['Week 2 Gross', '₹ 5.45 Cr', '₹ 25.1 Cr', '₹ 4.05 Cr', '₹ 2.6 Cr', '₹ 45.85 Cr', '₹ 83.05 Cr']\n",
      "['Day 15 [3rd Friday]', '₹ 0.3 Cr', '₹ 0.65 Cr', '₹ 0.25 Cr', '₹ 0.1 Cr', '₹ 3.05 Cr', '₹ 4.35 Cr']\n",
      "['Day 16 [3rd Saturday]', '₹ 0.47 Cr', '₹ 1.15 Cr', '₹ 0.35 Cr', '₹ 0.13 Cr', '₹ 4.4 Cr', '₹ 6.5 Cr']\n",
      "['Day 17 [3rd Sunday]', '₹ 0.55 Cr', '₹ 1.2 Cr', '₹ 0.4 Cr', '₹ 0.15 Cr', '₹ 4.9 Cr', '₹ 7.2 Cr']\n",
      "['Day 18 [3rd Monday]', '₹ 0.2 Cr', '₹ 0.45 Cr', '₹ 0.25 Cr', '₹ 0.05 Cr', '₹ 2 Cr', '₹ 2.95 Cr']\n",
      "['Day 19 [3rd Tuesday]', '₹ 0.17 Cr', '₹ 0.4 Cr', '₹ 0.23 Cr', '₹ 0.05 Cr', '₹ 1.85 Cr', '₹ 2.7 Cr']\n",
      "['Day 20 [3rd Wednesday]', '₹ 0.15 Cr', '₹ 0.4 Cr', '₹ 0.21 Cr', '₹ 0.04 Cr', '₹ 1.7 Cr', '₹ 2.5 Cr']\n",
      "['Day 21 [3rd Thursday]', '₹ 0.15 Cr', '₹ 0.37 Cr', '₹ 0.2 Cr', '₹ 0.03 Cr', '₹ 1.6 Cr', '₹ 2.35 Cr']\n",
      "['Week 3 Gross', '₹ 1.99 Cr', '₹ 4.62 Cr', '₹ 1.89 Cr', '₹ 0.55 Cr', '₹ 19.5 Cr', '₹ 28.55 Cr']\n",
      "['Total', '₹ 42.39 Cr', '₹ 221.62 Cr', '₹ 24.74 Cr', '₹ 17.05 Cr', '₹ 169.3 Cr', '₹ 475.1 Cr']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL you want to scrape\n",
    "url = \"https://www.sacnilk.com/news/_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "\n",
    "# Fetch the website\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# ---------- MOVIE NAME ----------\n",
    "title = soup.find(\"h1\").text\n",
    "print(\"Movie:\", title)\n",
    "print()\n",
    "\n",
    "# ---------- DAY-WISE COLLECTION ----------\n",
    "print(\"Day-wise Collection:\")\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    print(cols)\n",
    "\n",
    "print()\n",
    "\n",
    "# ---------- STATE-WISE COLLECTION ----------\n",
    "print(\"State-wise Collection:\")\n",
    "\n",
    "# Sacnilk usually has 2nd table for states\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        print(cols)\n",
    "else:\n",
    "    print(\"No state-wise data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fced4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Salaar Box Office Collection | Day Wise | Worldwide\n",
      "\n",
      "Detected columns: 3\n",
      "\n",
      "Saved → Salaar_raw.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.sacnilk.com/news/_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# Movie name\n",
    "title = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", title)\n",
    "\n",
    "# ---------- DAY-WISE TABLE ----------\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "rows = []\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    rows.append(cols)\n",
    "\n",
    "# Detect number of columns\n",
    "num_cols = len(rows[0])\n",
    "print(\"\\nDetected columns:\", num_cols)\n",
    "\n",
    "# Assign column names automatically\n",
    "if num_cols == 3:\n",
    "    col_names = [\"day\", \"india_net\", \"worldwide\"]\n",
    "elif num_cols == 4:\n",
    "    col_names = [\"day\", \"india_net\", \"india_gross\", \"worldwide\"]\n",
    "else:\n",
    "    col_names = [f\"col_{i+1}\" for i in range(num_cols)]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=col_names)\n",
    "\n",
    "# Add movie name & primary key\n",
    "df[\"movie_name\"] = title\n",
    "df[\"pk\"] = df[\"movie_name\"] + \"_\" + df[\"day\"]\n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"Salaar_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"\\nSaved → Salaar_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Salaar Box Office Collection | Day Wise | Worldwide\n",
      "\n",
      "Saved → Salaar_raw.csv\n",
      "                    day                                          india_net  \\\n",
      "0    Day 1 [1st Friday]  ₹ 90.7 Cr [Te: 66.75 Cr ; Mal: 3.55 Cr; Ta: 3....   \n",
      "1  Day 2 [1st Saturday]  ₹ 56.35 Cr [Te: 34.25 Cr ; Mal: 1.75 Cr; Ta: 3...   \n",
      "2    Day 3 [1st Sunday]  ₹ 62.05 Cr [Te: 35 Cr ; Mal: 1.55 Cr; Ta: 3.2 ...   \n",
      "3    Day 4 [1st Monday]  ₹ 46.3 Cr [Te: 27.1 Cr ; Mal: 1.3 Cr; Ta: 2.05...   \n",
      "4   Day 5 [1st Tuesday]  ₹ 24.9 Cr [Te: 13.7 Cr ; Mal: 0.7 Cr; Ta: 1.1 ...   \n",
      "\n",
      "  change_percent   karnataka       aptg tamil_nadu     kerala rest_of_india  \\\n",
      "0              -  ₹ 11.65 Cr  ₹ 67.1 Cr   ₹ 4.9 Cr  ₹ 4.65 Cr     ₹ 18.8 Cr   \n",
      "1        -37.87%   ₹ 7.25 Cr  ₹ 33.5 Cr     ₹ 4 Cr  ₹ 2.65 Cr     ₹ 19.3 Cr   \n",
      "2         10.12%    ₹ 6.7 Cr  ₹ 35.6 Cr   ₹ 4.1 Cr   ₹ 2.3 Cr     ₹ 24.8 Cr   \n",
      "3        -25.38%   ₹ 4.65 Cr  ₹ 28.4 Cr   ₹ 2.7 Cr   ₹ 1.8 Cr    ₹ 16.65 Cr   \n",
      "4        -46.22%    ₹ 2.2 Cr  ₹ 16.2 Cr   ₹ 1.1 Cr  ₹ 1.05 Cr     ₹ 8.85 Cr   \n",
      "\n",
      "    day_total                                         movie_name  \n",
      "0  ₹ 107.1 Cr  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "1   ₹ 66.7 Cr  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "2   ₹ 73.5 Cr  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "3   ₹ 54.2 Cr  Salaar Box Office Collection | Day Wise | Worl...  \n",
      "4   ₹ 29.4 Cr  Salaar Box Office Collection | Day Wise | Worl...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.sacnilk.com/news/_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ---------------------------- TABLE 1 (Day wise) ----------------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ---------------------------- TABLE 2 (State wise) ----------------------------\n",
    "state_table = tables[1]\n",
    "state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "state_rows = []\n",
    "for row in state_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if cols:\n",
    "        entry = {}\n",
    "        for i, col in enumerate(cols):\n",
    "            entry[state_header[i]] = col\n",
    "        state_rows.append(entry)\n",
    "\n",
    "df_state = pd.DataFrame(state_rows)\n",
    "\n",
    "# ---------------------------- MERGE BOTH TABLES ----------------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "df[\"movie_name\"] = movie_name\n",
    "\n",
    "df.to_csv(\"Salaar_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Salaar_raw.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb478f6",
   "metadata": {},
   "source": [
    "SALAAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35dbe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Salaar Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 200 Cr * Approx\n",
      "Verdict: Hit\n",
      "India Screens: India: 6000\n",
      "Overseas Screens: Overseas: 1000\n",
      "Worldwide Screens: Worldwide total: 7000\n",
      "Release Date: 14th April 2022For more and the latest news aboutBox Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → Salaar_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day                                          india_net  \\\n",
      "0    Day 1 [1st Friday]  ₹ 90.7 Cr [Te: 66.75 Cr ; Mal: 3.55 Cr; Ta: 3....   \n",
      "1  Day 2 [1st Saturday]  ₹ 56.35 Cr [Te: 34.25 Cr ; Mal: 1.75 Cr; Ta: 3...   \n",
      "2    Day 3 [1st Sunday]  ₹ 62.05 Cr [Te: 35 Cr ; Mal: 1.55 Cr; Ta: 3.2 ...   \n",
      "3    Day 4 [1st Monday]  ₹ 46.3 Cr [Te: 27.1 Cr ; Mal: 1.3 Cr; Ta: 2.05...   \n",
      "4   Day 5 [1st Tuesday]  ₹ 24.9 Cr [Te: 13.7 Cr ; Mal: 0.7 Cr; Ta: 1.1 ...   \n",
      "\n",
      "              budget verdict india_screens  \\\n",
      "0  ₹ 200 Cr * Approx     Hit   India: 6000   \n",
      "1  ₹ 200 Cr * Approx     Hit   India: 6000   \n",
      "2  ₹ 200 Cr * Approx     Hit   India: 6000   \n",
      "3  ₹ 200 Cr * Approx     Hit   India: 6000   \n",
      "4  ₹ 200 Cr * Approx     Hit   India: 6000   \n",
      "\n",
      "                                        release_date  \n",
      "0  14th April 2022For more and the latest news ab...  \n",
      "1  14th April 2022For more and the latest news ab...  \n",
      "2  14th April 2022For more and the latest news ab...  \n",
      "3  14th April 2022For more and the latest news ab...  \n",
      "4  14th April 2022For more and the latest news ab...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"Salaar_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Salaar_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949a3d9",
   "metadata": {},
   "source": [
    "SAAHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26da547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Saaho Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: India: 6500\n",
      "Overseas Screens: Overseas: 1500\n",
      "Worldwide Screens: Worldwide total: 8000\n",
      "Release Date: 30th Aug 2019Saaho Records-Saaho is the second-highest opening day collection movie in India [All Language] after Baahubali 2 [121 Cr].- Saaho may become the second-highest India Net collection movie in India [All Language] after Baahubali 2 [1030.42 Cr].-Saaho is the 10th highest India net collection movie of all time.-Saaho is the 39th highest Hindi net collection movie of all time.Story Line--For more and the latest news aboutBollywood and Tollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → Saaho_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day                                          india_net  \\\n",
      "0    Day 1 [1st Friday]  ₹ 89.00 Cr [Hi: 24.40; Ta: 3.20; Te: 60.40 ; M...   \n",
      "1  Day 2 [1st Saturday]  ₹ 55.10 Cr [Hi: 25.20; Ta: 2.20; Te: 27.10; Ma...   \n",
      "2    Day 3 [1st Sunday]  ₹ 56.78 Cr [Hi: 29.48; Ta: 1.60; Te: 25.30; Ma...   \n",
      "3    Day 4 [1st Monday]  ₹ 28.80 Cr [Hi: 14.20; Ta: 0.80; Te: 13.60; Ma...   \n",
      "4   Day 5 [1st Tuesday]  ₹ 15.60 Cr [Hi: 9.10; Ta: 0.40; Te: 6.00; Ma: ...   \n",
      "\n",
      "      budget    verdict india_screens  \\\n",
      "0  Not Found  Not Found   India: 6500   \n",
      "1  Not Found  Not Found   India: 6500   \n",
      "2  Not Found  Not Found   India: 6500   \n",
      "3  Not Found  Not Found   India: 6500   \n",
      "4  Not Found  Not Found   India: 6500   \n",
      "\n",
      "                                        release_date  \n",
      "0  30th Aug 2019Saaho Records-Saaho is the second...  \n",
      "1  30th Aug 2019Saaho Records-Saaho is the second...  \n",
      "2  30th Aug 2019Saaho Records-Saaho is the second...  \n",
      "3  30th Aug 2019Saaho Records-Saaho is the second...  \n",
      "4  30th Aug 2019Saaho Records-Saaho is the second...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Saaho_Box_Office_Collection_All_Language_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"Saaho_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Saaho_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98cf87",
   "metadata": {},
   "source": [
    "KALKI2898AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552432ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Kalki 2898 AD Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: ₹ 500 Cr * Approx\n",
      "Verdict: Blockbuster\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 27th June 2024For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → Kalki2898AD_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day india_net             budget      verdict  \\\n",
      "0  Day 1 [1st Thursday]   ₹ 11 Cr  ₹ 500 Cr * Approx  Blockbuster   \n",
      "1    Day 2 [1st Friday]    ₹ 6 Cr  ₹ 500 Cr * Approx  Blockbuster   \n",
      "2  Day 3 [1st Saturday]  ₹ 8.3 Cr  ₹ 500 Cr * Approx  Blockbuster   \n",
      "3    Day 4 [1st Sunday]  ₹ 9.8 Cr  ₹ 500 Cr * Approx  Blockbuster   \n",
      "4    Day 5 [1st Monday]  ₹ 3.3 Cr  ₹ 500 Cr * Approx  Blockbuster   \n",
      "\n",
      "  india_screens                                       release_date  \n",
      "0     Not Found  27th June 2024For more and the latest news abo...  \n",
      "1     Not Found  27th June 2024For more and the latest news abo...  \n",
      "2     Not Found  27th June 2024For more and the latest news abo...  \n",
      "3     Not Found  27th June 2024For more and the latest news abo...  \n",
      "4     Not Found  27th June 2024For more and the latest news abo...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Project_K_2024_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"Kalki2898AD_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Kalki2898AD_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f0d45",
   "metadata": {},
   "source": [
    "ADIPURUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d213bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Adipurush Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 450 Cr * Approx\n",
      "Verdict: Flop\n",
      "India Screens: India: 7000\n",
      "Overseas Screens: Overseas: 3000\n",
      "Worldwide Screens: Worldwide total: 10000\n",
      "Release Date: 16th June 2023For more and the latest news aboutBollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → Adipurush_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net             budget verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 13.7 Cr  ₹ 450 Cr * Approx    Flop   India: 7000   \n",
      "1  Day 2 [1st Saturday]  ₹ 7.78 Cr  ₹ 450 Cr * Approx    Flop   India: 7000   \n",
      "2    Day 3 [1st Sunday]  ₹ 8.15 Cr  ₹ 450 Cr * Approx    Flop   India: 7000   \n",
      "3    Day 4 [1st Monday]  ₹ 2.15 Cr  ₹ 450 Cr * Approx    Flop   India: 7000   \n",
      "4   Day 5 [1st Tuesday]  ₹ 1.22 Cr  ₹ 450 Cr * Approx    Flop   India: 7000   \n",
      "\n",
      "                                        release_date  \n",
      "0  16th June 2023For more and the latest news abo...  \n",
      "1  16th June 2023For more and the latest news abo...  \n",
      "2  16th June 2023For more and the latest news abo...  \n",
      "3  16th June 2023For more and the latest news abo...  \n",
      "4  16th June 2023For more and the latest news abo...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Adipurush_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"Adipurush_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Adipurush_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c720b0",
   "metadata": {},
   "source": [
    "RADHEYSHYAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cade5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Radhe Shyam Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 300 Cr* Approx\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 11th March 2022For more and the latest news aboutIndian Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → RadheyShyam_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net            budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 10.8 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]  ₹ 6.65 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]  ₹ 4.95 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 0.97 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 0.55 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  11th March 2022For more and the latest news ab...  \n",
      "1  11th March 2022For more and the latest news ab...  \n",
      "2  11th March 2022For more and the latest news ab...  \n",
      "3  11th March 2022For more and the latest news ab...  \n",
      "4  11th March 2022For more and the latest news ab...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Radhe_Shyam_2021_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"RadheyShyam_raw.csv\", index=False)\n",
    "print(\"\\nSaved → RadheyShyam_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48be677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Radhe Shyam Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 300 Cr* Approx\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 11th March 2022For more and the latest news aboutIndian Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → RadheyShyam_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net            budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 10.8 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]  ₹ 6.65 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]  ₹ 4.95 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 0.97 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 0.55 Cr  ₹ 300 Cr* Approx  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  11th March 2022For more and the latest news ab...  \n",
      "1  11th March 2022For more and the latest news ab...  \n",
      "2  11th March 2022For more and the latest news ab...  \n",
      "3  11th March 2022For more and the latest news ab...  \n",
      "4  11th March 2022For more and the latest news ab...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Radhe_Shyam_2021_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"RadheyShyam_raw.csv\", index=False)\n",
    "print(\"\\nSaved → RadheyShyam_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edfa3cf",
   "metadata": {},
   "source": [
    "CONCAT ALL PRABHAS MOVIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdef5a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 movies: ['Adipurush_raw.csv', 'Kalki2898AD_raw.csv', 'RadheyShyam_raw.csv', 'Saaho_raw.csv', 'Salaar_raw.csv']\n",
      "Processing (1/5): Adipurush_raw.csv\n",
      "Processing (2/5): Kalki2898AD_raw.csv\n",
      "Processing (3/5): RadheyShyam_raw.csv\n",
      "Processing (4/5): Saaho_raw.csv\n",
      "Processing (5/5): Salaar_raw.csv\n",
      "\n",
      "SUCCESS! ALL MOVIES COMBINED\n",
      "Total rows: 140\n",
      "Total movies: 5\n",
      "Unique movie_ids: [1, 2, 3, 4, 5]\n",
      "\n",
      "Files saved:\n",
      "   TFI_MASTER_DATASET.csv\n",
      "   TFI_MASTER_DATASET.xlsx  ← Open in Power BI!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ------------------- AUTO FIND ALL YOUR RAW FILES -------------------\n",
    "files = glob.glob(\"*_raw.csv\")\n",
    "\n",
    "if not files:\n",
    "    print(\"No *_raw.csv files found!\")\n",
    "else:\n",
    "    print(f\"Found {len(files)} movies: {files}\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, file in enumerate(files, start=1):  # movie_id starts from 1\n",
    "    print(f\"Processing ({i}/{len(files)}): {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # --- Extract clean movie name ---\n",
    "    raw_name = os.path.splitext(file)[0].replace(\"_raw\", \"\")\n",
    "    if 'movie_name' in df.columns and df['movie_name'].notna().any():\n",
    "        movie_name = df['movie_name'].iloc[0].split(\" Box Office\")[0].strip()\n",
    "    else:\n",
    "        movie_name = raw_name\n",
    "\n",
    "    # --- Add essential columns ---\n",
    "    df[\"movie\"] = movie_name\n",
    "    df[\"movie_id\"] = i  # Unique ID: 1,2,3,...\n",
    "\n",
    "    # --- Create primary_key safely (only if 'day' exists) ---\n",
    "    if 'day' in df.columns:\n",
    "        df[\"primary_key\"] = df[\"movie\"] + \" | \" + df[\"day\"].astype(str)\n",
    "    else:\n",
    "        df[\"primary_key\"] = df[\"movie\"] + \" | Row_\" + df.index.astype(str)\n",
    "\n",
    "    # --- Keep only useful columns (safe even if some are missing) ---\n",
    "    desired_cols = [\n",
    "        \"movie_id\", \"movie\", \"day\", \"india_net\", \"change_percent\",\n",
    "        \"karnataka\", \"aptg\", \"tamil_nadu\", \"kerala\", \"rest_of_india\", \"day_total\",\n",
    "        \"budget\", \"verdict\", \"india_screens\", \"overseas_screens\",\n",
    "        \"worldwide_screens\", \"release_date\", \"primary_key\"\n",
    "    ]\n",
    "    df = df[[col for col in desired_cols if col in df.columns]]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# ------------------- COMBINE ALL -------------------\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Drop duplicates using primary_key (now it exists in ALL dataframes)\n",
    "combined_df.drop_duplicates(subset=[\"primary_key\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# Sort by movie_id and day number\n",
    "combined_df[\"day_num\"] = combined_df[\"day\"].str.extract(r'(\\d+)').astype(float).fillna(999)\n",
    "combined_df = combined_df.sort_values([\"movie_id\", \"day_num\"]).drop(columns=[\"day_num\"], errors=\"ignore\")\n",
    "\n",
    "# Final cleanup\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ------------------- SAVE FINAL FILES -------------------\n",
    "combined_df.to_csv(\"TFI_MASTER_DATASET.csv\", index=False)\n",
    "combined_df.to_excel(\"TFI_MASTER_DATASET.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nSUCCESS! ALL MOVIES COMBINED\")\n",
    "print(f\"Total rows: {len(combined_df):,}\")\n",
    "print(f\"Total movies: {combined_df['movie'].nunique()}\")\n",
    "print(f\"Unique movie_ids: {sorted(combined_df['movie_id'].unique())}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"   TFI_MASTER_DATASET.csv\")\n",
    "print(\"   TFI_MASTER_DATASET.xlsx  ← Open in Power BI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd5908",
   "metadata": {},
   "source": [
    "ALLU ARJUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe22302",
   "metadata": {},
   "source": [
    "NAA PERU SURYA NAA ILLU INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fc04f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Naa Peru Surya Naa Illu India\n",
      "Saved → NPS_raw.csv\n",
      "Empty DataFrame\n",
      "Columns: [movie, hero, budget, verdict, release_date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.boxofficeandhra.com/2018/06/naa-peru-surya-total-worldwide.html\"\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = \"Naa Peru Surya Naa Illu India\"\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# Find the main collections table (week-wise)\n",
    "table = soup.find(\"table\", {\"class\": \"table table-striped\"})  # Adjust class if needed\n",
    "if not table:\n",
    "    table = soup.find(\"table\")  # Fallback to first table\n",
    "\n",
    "rows = []\n",
    "if table:\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip header\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if len(cols) >= 2:\n",
    "            rows.append({\n",
    "                \"week\": cols[0],\n",
    "                \"india_net\": cols[1],\n",
    "                \"worldwide_gross\": cols[2] if len(cols) > 2 else None\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"movie\"] = movie_name\n",
    "df[\"hero\"] = \"Allu Arjun\"\n",
    "df[\"budget\"] = \"₹ 55 Cr\"\n",
    "df[\"verdict\"] = \"Semi-Hit\"\n",
    "df[\"release_date\"] = \"27th April 2018\"\n",
    "\n",
    "df.to_csv(\"NPS_raw.csv\", index=False)\n",
    "print(\"Saved → NPS_raw.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90f522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Ala Vaikunthapurramloo Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 120 Cr * Approx\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 12th January 2020For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → AVPL_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                     day  india_net             budget    verdict  \\\n",
      "0     Day 1 [1st Sunday]  ₹ 5.90 Cr  ₹ 120 Cr * Approx  Not Found   \n",
      "1     Day 2 [1st Monday]  ₹ 4.00 Cr  ₹ 120 Cr * Approx  Not Found   \n",
      "2    Day 3 [1st Tuesday]  ₹ 4.10 Cr  ₹ 120 Cr * Approx  Not Found   \n",
      "3  Day 4 [1st Wednesday]  ₹ 4.50 Cr  ₹ 120 Cr * Approx  Not Found   \n",
      "4   Day 5 [1st Thursday]  ₹ 4.10 Cr  ₹ 120 Cr * Approx  Not Found   \n",
      "\n",
      "  india_screens                                       release_date  \n",
      "0     Not Found  12th January 2020For more and the latest news ...  \n",
      "1     Not Found  12th January 2020For more and the latest news ...  \n",
      "2     Not Found  12th January 2020For more and the latest news ...  \n",
      "3     Not Found  12th January 2020For more and the latest news ...  \n",
      "4     Not Found  12th January 2020For more and the latest news ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Ala_Vaikunthapurramloo_2020_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"AVPL_raw.csv\", index=False)\n",
    "print(\"\\nSaved → AVPL_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581bb2c",
   "metadata": {},
   "source": [
    "PAWAN KALYAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: They Call Him OG Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 25th September 2025For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → OG_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day india_net     budget    verdict india_screens  \\\n",
      "0    Day 0 [ Wednesday]  ₹ 2.7 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 1 [1st Thursday]  ₹ 6.8 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 2 [1st Friday]    ₹ 2 Cr  Not Found  Not Found     Not Found   \n",
      "3  Day 3 [1st Saturday]  ₹ 2.6 Cr  Not Found  Not Found     Not Found   \n",
      "4    Day 4 [1st Sunday]  ₹ 2.1 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  25th September 2025For more and the latest new...  \n",
      "1  25th September 2025For more and the latest new...  \n",
      "2  25th September 2025For more and the latest new...  \n",
      "3  25th September 2025For more and the latest new...  \n",
      "4  25th September 2025For more and the latest new...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/OG_2024_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"OG_raw.csv\", index=False)\n",
    "print(\"\\nSaved → OG_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2da527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Bro Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 28th July 2023For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → BRO_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 8.45 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]   ₹ 4.8 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 4.2 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 0.99 Cr  Not Found  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 0.72 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  28th July 2023For more and the latest news abo...  \n",
      "1  28th July 2023For more and the latest news abo...  \n",
      "2  28th July 2023For more and the latest news abo...  \n",
      "3  28th July 2023For more and the latest news abo...  \n",
      "4  28th July 2023For more and the latest news abo...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/PKSDT_2023_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"BRO_raw.csv\", index=False)\n",
    "print(\"\\nSaved → BRO_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28125644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Bheemla Nayak Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: ₹ 80 Cr * Approx\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 25 Feb 2022For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → BN_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day   india_net            budget    verdict  \\\n",
      "0    Day 1 [1st Friday]  ₹ 11.85 Cr  ₹ 80 Cr * Approx  Not Found   \n",
      "1  Day 2 [1st Saturday]    ₹ 7.5 Cr  ₹ 80 Cr * Approx  Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 6.55 Cr  ₹ 80 Cr * Approx  Not Found   \n",
      "3    Day 4 [1st Monday]   ₹ 2.39 Cr  ₹ 80 Cr * Approx  Not Found   \n",
      "4   Day 5 [1st Tuesday]   ₹ 2.93 Cr  ₹ 80 Cr * Approx  Not Found   \n",
      "\n",
      "  india_screens                                       release_date  \n",
      "0     Not Found  25 Feb 2022For more and the latest news aboutT...  \n",
      "1     Not Found  25 Feb 2022For more and the latest news aboutT...  \n",
      "2     Not Found  25 Feb 2022For more and the latest news aboutT...  \n",
      "3     Not Found  25 Feb 2022For more and the latest news aboutT...  \n",
      "4     Not Found  25 Feb 2022For more and the latest news aboutT...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/PSPK_Rana_Movie_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"BN_raw.csv\", index=False)\n",
    "print(\"\\nSaved → BN_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9660461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Vakeel Saab Box Office Collection | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: India: 1500\n",
      "Overseas Screens: Overseas: 700\n",
      "Worldwide Screens: Worldwide total: 2200\n",
      "Release Date: 9th April 2021For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → VK_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 8.75 Cr  Not Found  Not Found   India: 1500   \n",
      "1  Day 2 [1st Saturday]   ₹ 3.6 Cr  Not Found  Not Found   India: 1500   \n",
      "2    Day 3 [1st Sunday]   ₹ 3.9 Cr  Not Found  Not Found   India: 1500   \n",
      "3    Day 4 [1st Monday]   ₹ 1.1 Cr  Not Found  Not Found   India: 1500   \n",
      "4   Day 5 [1st Tuesday]   ₹ 2.9 Cr  Not Found  Not Found   India: 1500   \n",
      "\n",
      "                                        release_date  \n",
      "0  9th April 2021For more and the latest news abo...  \n",
      "1  9th April 2021For more and the latest news abo...  \n",
      "2  9th April 2021For more and the latest news abo...  \n",
      "3  9th April 2021For more and the latest news abo...  \n",
      "4  9th April 2021For more and the latest news abo...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/PSPK_26_2020_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"VK_raw.csv\", index=False)\n",
    "print(\"\\nSaved → VK_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885553d9",
   "metadata": {},
   "source": [
    "MAHESH BABU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc9a0edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Guntur Kaaram Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: ₹ 150 Cr * Approx\n",
      "Verdict: Average\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 12th January 2024For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → GK_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net             budget  verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]   ₹ 4.2 Cr  ₹ 150 Cr * Approx  Average     Not Found   \n",
      "1  Day 2 [1st Saturday]  ₹ 2.05 Cr  ₹ 150 Cr * Approx  Average     Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 1.6 Cr  ₹ 150 Cr * Approx  Average     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 1.05 Cr  ₹ 150 Cr * Approx  Average     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 0.52 Cr  ₹ 150 Cr * Approx  Average     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  12th January 2024For more and the latest news ...  \n",
      "1  12th January 2024For more and the latest news ...  \n",
      "2  12th January 2024For more and the latest news ...  \n",
      "3  12th January 2024For more and the latest news ...  \n",
      "4  12th January 2024For more and the latest news ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/SSMB28_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"GK_raw.csv\", index=False)\n",
    "print(\"\\nSaved → GK_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25efdfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Sarkaru Vaari Paata Box Office Collection | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 12th May 2022For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → SVP_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day india_net     budget    verdict india_screens  \\\n",
      "0  Day 1 [1st Thursday]  ₹ 3.6 Cr  Not Found  Not Found     Not Found   \n",
      "1    Day 2 [1st Friday]  ₹ 1.6 Cr  Not Found  Not Found     Not Found   \n",
      "2  Day 3 [1st Saturday]  ₹ 2.2 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Sunday]    ₹ 2 Cr  Not Found  Not Found     Not Found   \n",
      "4    Day 5 [1st Monday]  ₹ 0.4 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  12th May 2022For more and the latest news abou...  \n",
      "1  12th May 2022For more and the latest news abou...  \n",
      "2  12th May 2022For more and the latest news abou...  \n",
      "3  12th May 2022For more and the latest news abou...  \n",
      "4  12th May 2022For more and the latest news abou...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Sarkaru_Vari_Pata_2021_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"SVP_raw.csv\", index=False)\n",
    "print(\"\\nSaved → SVP_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b00f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Sarileru Neekevvaru Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 100.00 Cr * Approx\n",
      "Verdict: Blockbuster\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 11th January 2020For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → SLN_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                     day  india_net                budget      verdict  \\\n",
      "0   Day 1 [1st Saturday]  ₹ 8.66 Cr  ₹ 100.00 Cr * Approx  Blockbuster   \n",
      "1     Day 2 [1st Sunday]  ₹ 4.02 Cr  ₹ 100.00 Cr * Approx  Blockbuster   \n",
      "2     Day 3 [1st Monday]  ₹ 3.30 Cr  ₹ 100.00 Cr * Approx  Blockbuster   \n",
      "3    Day 4 [1st Tuesday]  ₹ 3.40 Cr  ₹ 100.00 Cr * Approx  Blockbuster   \n",
      "4  Day 5 [1st Wednesday]  ₹ 3.12 Cr  ₹ 100.00 Cr * Approx  Blockbuster   \n",
      "\n",
      "  india_screens                                       release_date  \n",
      "0     Not Found  11th January 2020For more and the latest news ...  \n",
      "1     Not Found  11th January 2020For more and the latest news ...  \n",
      "2     Not Found  11th January 2020For more and the latest news ...  \n",
      "3     Not Found  11th January 2020For more and the latest news ...  \n",
      "4     Not Found  11th January 2020For more and the latest news ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Sarileru_Neekevvaru_2020_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"SLN_raw.csv\", index=False)\n",
    "print(\"\\nSaved → SLN_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d264d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Maharshi Box Office Collection | Telugu | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 9th May 2019Maharshi Records- Highest Pre-release business for Mahesh Babu.-Note: Data as of 9th May 2019Story Line-Rishi, a millionaire businessman, returns to his homeland, where he becomes the champion of poor and downtrodden farmers. Directed by Vamsi Paidipally, Maharshi features Mahesh Babu and Pooja Hegde in central roles.For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → Maharshi_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day   india_net     budget    verdict india_screens  \\\n",
      "0  Day 1 [1st Thursday]  ₹ 34.75 Cr  Not Found  Not Found     Not Found   \n",
      "1    Day 2 [1st Friday]  ₹ 12.00 Cr  Not Found  Not Found     Not Found   \n",
      "2  Day 3 [1st Saturday]  ₹ 12.40 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Sunday]  ₹ 12.90 Cr  Not Found  Not Found     Not Found   \n",
      "4    Day 5 [1st Monday]   ₹ 6.20 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  9th May 2019Maharshi Records- Highest Pre-rele...  \n",
      "1  9th May 2019Maharshi Records- Highest Pre-rele...  \n",
      "2  9th May 2019Maharshi Records- Highest Pre-rele...  \n",
      "3  9th May 2019Maharshi Records- Highest Pre-rele...  \n",
      "4  9th May 2019Maharshi Records- Highest Pre-rele...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Maharshi_Box_Office_Collection_Telugu_Worldwide\"    \n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"Maharshi_raw.csv\", index=False)\n",
    "print(\"\\nSaved → Maharshi_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcab14e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: War 2 Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: ₹ 400 Cr * Approx\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 14th August 2025For more and the latest news aboutBollywood Box Office Collection, Stay tuned to us.War 2 State Wise Gross CollectionDayKarnatakaAPTGTamil NaduKeralaRest Of IndiaDay TotalDay 1 [1st Thursday]₹ 4 Cr₹ 27 Cr₹ 1.1 Cr₹ 0.5 Cr₹ 30 Cr₹ 62.6 CrDay 2 [1st Friday]₹ 4.6 Cr₹ 14.5 Cr₹ 1.25 Cr₹ 0.45 Cr₹ 48 Cr₹ 68.8 CrDay 3 [1st Saturday]₹ 3.1 Cr₹ 8.25 Cr₹ 1.1 Cr₹ 0.25 Cr₹ 26.8 Cr₹ 39.5 CrDay 4 [1st Sunday]₹ 2.75 Cr₹ 7 Cr₹ 1.02 Cr₹ 0.33 Cr₹ 27.75 Cr₹ 38.85 CrDay 5 [1st Monday]₹ 0.75 Cr₹ 1.75 Cr₹ 0.4 Cr₹ 0.15 Cr₹ 7.5 Cr₹ 10.55 CrDay 6 [1st Tuesday]₹ 0.75 Cr₹ 1.5 Cr₹ 0.22 Cr₹ 0.13 Cr₹ 8.2 Cr₹ 10.8 CrDay 7 [1st Wednesday]₹ 0.45 Cr₹ 1.3 Cr₹ 0.25 Cr₹ 0.05 Cr₹ 4.85 Cr₹ 6.9 CrDay 8 [2nd Thursday]₹ 0.4 Cr₹ 1.1 Cr₹ 0.22 Cr₹ 0.03 Cr₹ 4.1 Cr₹ 5.85 CrWeek 1 Gross₹ 16.8 Cr₹ 62.4 Cr₹ 5.56 Cr₹ 1.89 Cr₹ 157.2 Cr₹ 243.85 CrTotal₹ 16.8 Cr₹ 62.4 Cr₹ 5.56 Cr₹ 1.89 Cr₹ 157.2 Cr₹ 243.85 CrDisclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → WAR2_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day                                          india_net  \\\n",
      "0  Day 1 [1st Thursday]    ₹ 52 Cr [Hi: 29 Cr ; Ta: 0.25 Cr; Te: 22.75 Cr]   \n",
      "1    Day 2 [1st Friday]  ₹ 57.85 Cr [Hi: 45 Cr ; Ta: 0.35 Cr; Te: 12.5 Cr]   \n",
      "2  Day 3 [1st Saturday]   ₹ 33.25 Cr [Hi: 26 Cr ; Ta: 0.3 Cr; Te: 6.95 Cr]   \n",
      "3    Day 4 [1st Sunday]   ₹ 32.65 Cr [Hi: 27 Cr ; Ta: 0.3 Cr; Te: 5.35 Cr]   \n",
      "4    Day 5 [1st Monday]     ₹ 8.75 Cr [Hi: 7 Cr ; Ta: 0.15 Cr; Te: 1.6 Cr]   \n",
      "\n",
      "              budget    verdict india_screens  \\\n",
      "0  ₹ 400 Cr * Approx  Not Found     Not Found   \n",
      "1  ₹ 400 Cr * Approx  Not Found     Not Found   \n",
      "2  ₹ 400 Cr * Approx  Not Found     Not Found   \n",
      "3  ₹ 400 Cr * Approx  Not Found     Not Found   \n",
      "4  ₹ 400 Cr * Approx  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  14th August 2025For more and the latest news a...  \n",
      "1  14th August 2025For more and the latest news a...  \n",
      "2  14th August 2025For more and the latest news a...  \n",
      "3  14th August 2025For more and the latest news a...  \n",
      "4  14th August 2025For more and the latest news a...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/War_2_2024_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"WAR2_raw.csv\", index=False)\n",
    "print(\"\\nSaved → WAR2_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46941c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Devara - Part 1 Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 27th September 2024For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → SLM_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 10.5 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]   ₹ 5.6 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 4.8 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 1.55 Cr  Not Found  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]   ₹ 1.8 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  27th September 2024For more and the latest new...  \n",
      "1  27th September 2024For more and the latest new...  \n",
      "2  27th September 2024For more and the latest new...  \n",
      "3  27th September 2024For more and the latest new...  \n",
      "4  27th September 2024For more and the latest new...  \n",
      "Movie: Devara - Part 1 Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 27th September 2024For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → devara_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 10.5 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]   ₹ 5.6 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 4.8 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 1.55 Cr  Not Found  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]   ₹ 1.8 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  27th September 2024For more and the latest new...  \n",
      "1  27th September 2024For more and the latest new...  \n",
      "2  27th September 2024For more and the latest new...  \n",
      "3  27th September 2024For more and the latest new...  \n",
      "4  27th September 2024For more and the latest new...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/NTR_30_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/NTR_30_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"SLN_raw.csv\", index=False)\n",
    "print(\"\\nSaved → SLM_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"devara_raw.csv\", index=False)\n",
    "print(\"\\nSaved → devara_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd903049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: RRR Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Blockbuster\n",
      "India Screens: India: 9000\n",
      "Overseas Screens: Overseas: 6000\n",
      "Worldwide Screens: Worldwide total: 15000\n",
      "Release Date: 25th March 2022For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → RRR_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day   india_net     budget      verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]  ₹ 23.35 Cr  Not Found  Blockbuster   India: 9000   \n",
      "1  Day 2 [1st Saturday]   ₹ 15.1 Cr  Not Found  Blockbuster   India: 9000   \n",
      "2    Day 3 [1st Sunday]  ₹ 15.05 Cr  Not Found  Blockbuster   India: 9000   \n",
      "3    Day 4 [1st Monday]   ₹ 8.15 Cr  Not Found  Blockbuster   India: 9000   \n",
      "4   Day 5 [1st Tuesday]    ₹ 6.7 Cr  Not Found  Blockbuster   India: 9000   \n",
      "\n",
      "                                        release_date  \n",
      "0  25th March 2022For more and the latest news ab...  \n",
      "1  25th March 2022For more and the latest news ab...  \n",
      "2  25th March 2022For more and the latest news ab...  \n",
      "3  25th March 2022For more and the latest news ab...  \n",
      "4  25th March 2022For more and the latest news ab...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/RRR_2020_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"RRR_raw.csv\", index=False)\n",
    "print(\"\\nSaved → RRR_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3fff7",
   "metadata": {},
   "source": [
    "RAMCHARAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8a4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Game Changer Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 10th January 2025For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → GC.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]   ₹ 4.5 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 2 [1st Saturday]   ₹ 2.2 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 3 [1st Sunday]   ₹ 1.3 Cr  Not Found  Not Found     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 0.65 Cr  Not Found  Not Found     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 0.85 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  10th January 2025For more and the latest news ...  \n",
      "1  10th January 2025For more and the latest news ...  \n",
      "2  10th January 2025For more and the latest news ...  \n",
      "3  10th January 2025For more and the latest news ...  \n",
      "4  10th January 2025For more and the latest news ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/RC15_2022_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"GC.csv\", index=False)\n",
    "print(\"\\nSaved → GC.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d041a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Vinaya Vidheya Rama Box Office Collection | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Flop\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 11th January 2019Vinaya Vidheya Rama Records- Third highest opening in Telugu after Baahubali 2 and Agnyathavasi. [all time record]\n",
      "\n",
      "Saved → VVR_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget verdict india_screens  \\\n",
      "0    Day 1 [1st Friday]    ₹ 34 Cr  Not Found    Flop     Not Found   \n",
      "1  Day 2 [1st Saturday]  ₹ 6.20 Cr  Not Found    Flop     Not Found   \n",
      "2    Day 3 [1st Sunday]  ₹ 4.50 Cr  Not Found    Flop     Not Found   \n",
      "3    Day 4 [1st Monday]  ₹ 5.20 Cr  Not Found    Flop     Not Found   \n",
      "4   Day 5 [1st Tuesday]  ₹ 7.20 Cr  Not Found    Flop     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  11th January 2019Vinaya Vidheya Rama Records- ...  \n",
      "1  11th January 2019Vinaya Vidheya Rama Records- ...  \n",
      "2  11th January 2019Vinaya Vidheya Rama Records- ...  \n",
      "3  11th January 2019Vinaya Vidheya Rama Records- ...  \n",
      "4  11th January 2019Vinaya Vidheya Rama Records- ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Vinaya_Vidheya_Rama_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"VVR_raw.csv\", index=False)\n",
    "print(\"\\nSaved → VVR_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de55903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Pushpa: The Rule - Part 2 Box Office Collection | All Language | Day Wise | Worldwide\n",
      "Budget: Not Found\n",
      "Verdict: Not Found\n",
      "India Screens: Not Found\n",
      "Overseas Screens: Not Found\n",
      "Worldwide Screens: Not Found\n",
      "Release Date: 5th December 2024For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → p2_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day  india_net     budget    verdict india_screens  \\\n",
      "0    Day 0 [ Wednesday]  ₹ 2.35 Cr  Not Found  Not Found     Not Found   \n",
      "1  Day 1 [1st Thursday]  ₹ 16.9 Cr  Not Found  Not Found     Not Found   \n",
      "2    Day 2 [1st Friday]  ₹ 8.55 Cr  Not Found  Not Found     Not Found   \n",
      "3  Day 3 [1st Saturday]  ₹ 11.7 Cr  Not Found  Not Found     Not Found   \n",
      "4    Day 4 [1st Sunday]  ₹ 13.4 Cr  Not Found  Not Found     Not Found   \n",
      "\n",
      "                                        release_date  \n",
      "0  5th December 2024For more and the latest news ...  \n",
      "1  5th December 2024For more and the latest news ...  \n",
      "2  5th December 2024For more and the latest news ...  \n",
      "3  5th December 2024For more and the latest news ...  \n",
      "4  5th December 2024For more and the latest news ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Pushpa_The_Rule_2021_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"p2_raw.csv\", index=False)\n",
    "print(\"\\nSaved → p2_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38476c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Pushpa - The Rise Box Office Collection | Day Wise | Worldwide\n",
      "Budget: ₹ 150 Cr * Approx\n",
      "Verdict: Not Found\n",
      "India Screens: India: 3000\n",
      "Overseas Screens: Overseas: 1000\n",
      "Worldwide Screens: Worldwide total: 4000\n",
      "Release Date: 17th Dec 2021For more and the latest news aboutTollywood Box Office Collection, Stay tuned to us.Disclaimer: The Box Office Data are compiled from various sources and by our own research.\n",
      "\n",
      "Saved → p1_raw.csv\n",
      "\n",
      "First 5 rows:\n",
      "                    day   india_net             budget    verdict  \\\n",
      "0    Day 1 [1st Friday]  ₹ 11.44 Cr  ₹ 150 Cr * Approx  Not Found   \n",
      "1  Day 2 [1st Saturday]    ₹ 7.4 Cr  ₹ 150 Cr * Approx  Not Found   \n",
      "2    Day 3 [1st Sunday]    ₹ 7.1 Cr  ₹ 150 Cr * Approx  Not Found   \n",
      "3    Day 4 [1st Monday]   ₹ 3.35 Cr  ₹ 150 Cr * Approx  Not Found   \n",
      "4   Day 5 [1st Tuesday]    ₹ 1.8 Cr  ₹ 150 Cr * Approx  Not Found   \n",
      "\n",
      "  india_screens                                       release_date  \n",
      "0   India: 3000  17th Dec 2021For more and the latest news abou...  \n",
      "1   India: 3000  17th Dec 2021For more and the latest news abou...  \n",
      "2   India: 3000  17th Dec 2021For more and the latest news abou...  \n",
      "3   India: 3000  17th Dec 2021For more and the latest news abou...  \n",
      "4   India: 3000  17th Dec 2021For more and the latest news abou...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------- CHANGE ONLY THIS LINE FOR OTHER MOVIES -------------------\n",
    "url = \"https://www.sacnilk.com/news/Pushpa_2020_Box_Office_Collection_Day_Wise_Worldwide\"\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "page = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "movie_name = soup.find(\"h1\").text.strip()\n",
    "print(\"Movie:\", movie_name)\n",
    "\n",
    "# ------------------- FIXED: GRAB BUDGET, VERDICT, SCREENS, RELEASE DATE -------------------\n",
    "# Search for specific elements with keywords (handles HTML structure like <strong>)\n",
    "budget = \"Not Found\"\n",
    "verdict = \"Not Found\"\n",
    "india_screens = \"Not Found\"\n",
    "overseas_screens = \"Not Found\"\n",
    "worldwide_screens = \"Not Found\"\n",
    "release_date = \"Not Found\"\n",
    "\n",
    "# Find all relevant text containers (p, div, span, etc.)\n",
    "all_elements = soup.find_all(['p', 'div', 'span', 'strong'])\n",
    "\n",
    "for elem in all_elements:\n",
    "    text = elem.get_text(strip=True)\n",
    "    \n",
    "    # Budget\n",
    "    if \"Budget:\" in text:\n",
    "        budget_match = re.search(r'Budget:\\s*(₹\\s*\\d+(?:\\.\\d+)?\\s*Cr\\s*\\*\\s*Approx)', text)\n",
    "        if budget_match:\n",
    "            budget = budget_match.group(1).strip()\n",
    "    \n",
    "    # Verdict (look for <strong>Salaar Verdict:</strong> <strong>Hit</strong>)\n",
    "    if \"Verdict:\" in text:\n",
    "        # Get the next sibling or parent text for the value\n",
    "        verdict_elem = elem.find_next_sibling('strong') or elem.parent.find('strong')\n",
    "        if verdict_elem:\n",
    "            verdict = verdict_elem.get_text(strip=True)\n",
    "        else:\n",
    "            # Fallback regex for plain text\n",
    "            verdict_match = re.search(r'Verdict:\\s*(Hit|Flop|Blockbuster|Super Hit|Average|Disaster)', text)\n",
    "            verdict = verdict_match.group(1).strip() if verdict_match else \"Not Found\"\n",
    "    \n",
    "    # Screen counts (look for lines with numbers after labels)\n",
    "    if \"India:\" in text and re.search(r'\\d+', text):\n",
    "        india_match = re.search(r'India:\\s*(\\d+)', text)\n",
    "        if india_match:\n",
    "            india_screens = f\"India: {india_match.group(1)}\"\n",
    "    if \"Overseas:\" in text and re.search(r'\\d+', text):\n",
    "        overseas_match = re.search(r'Overseas:\\s*(\\d+)', text)\n",
    "        if overseas_match:\n",
    "            overseas_screens = f\"Overseas: {overseas_match.group(1)}\"\n",
    "    if \"Worldwide total:\" in text and re.search(r'\\d+', text):\n",
    "        worldwide_match = re.search(r'Worldwide total:\\s*(\\d+)', text)\n",
    "        if worldwide_match:\n",
    "            worldwide_screens = f\"Worldwide total: {worldwide_match.group(1)}\"\n",
    "    \n",
    "    # Release Date\n",
    "    if \"Release Date:\" in text:\n",
    "        release_match = re.search(r'Release Date:\\s*(.+)', text)\n",
    "        if release_match:\n",
    "            release_date = release_match.group(1).strip()\n",
    "\n",
    "print(\"Budget:\", budget)\n",
    "print(\"Verdict:\", verdict)\n",
    "print(\"India Screens:\", india_screens)\n",
    "print(\"Overseas Screens:\", overseas_screens)\n",
    "print(\"Worldwide Screens:\", worldwide_screens)\n",
    "print(\"Release Date:\", release_date)\n",
    "\n",
    "# ------------------- TABLE 1 (Day wise) -------------------\n",
    "tables = soup.find_all(\"table\")\n",
    "daywise_table = tables[0]\n",
    "rows = []\n",
    "\n",
    "for row in daywise_table.find_all(\"tr\")[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "    if len(cols) >= 2:\n",
    "        rows.append({\n",
    "            \"day\": cols[0],\n",
    "            \"india_net\": cols[1],\n",
    "            \"change_percent\": cols[2] if len(cols) > 2 else None\n",
    "        })\n",
    "\n",
    "df_daywise = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------- TABLE 2 (State wise) -------------------\n",
    "if len(tables) > 1:\n",
    "    state_table = tables[1]\n",
    "    state_header = [th.text.strip().replace(\" \", \"_\").lower() for th in state_table.find_all(\"th\")]\n",
    "\n",
    "    state_rows = []\n",
    "    for row in state_table.find_all(\"tr\")[1:]:\n",
    "        cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            entry = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                if i < len(state_header):\n",
    "                    entry[state_header[i]] = col\n",
    "            state_rows.append(entry)\n",
    "\n",
    "    df_state = pd.DataFrame(state_rows)\n",
    "else:\n",
    "    df_state = pd.DataFrame()  # empty if no state table\n",
    "\n",
    "# ------------------- MERGE BOTH TABLES -------------------\n",
    "df = pd.merge(df_daywise, df_state, left_on=\"day\", right_on=\"day\", how=\"left\")\n",
    "\n",
    "# ------------------- ADD ALL NEW INFO -------------------\n",
    "df[\"movie_name\"] = movie_name\n",
    "df[\"budget\"] = budget\n",
    "df[\"verdict\"] = verdict\n",
    "df[\"india_screens\"] = india_screens\n",
    "df[\"overseas_screens\"] = overseas_screens\n",
    "df[\"worldwide_screens\"] = worldwide_screens\n",
    "df[\"release_date\"] = release_date\n",
    "\n",
    "# ------------------- SAVE TO CSV -------------------\n",
    "df.to_csv(\"p1_raw.csv\", index=False)\n",
    "print(\"\\nSaved → p1_raw.csv\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[[\"day\", \"india_net\", \"budget\", \"verdict\", \"india_screens\", \"release_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74525968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_name,total_WW_cls,hero_name,verdict,day1_in_cr\n",
      "N/A,N/A,N/A,N/A,N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def scrape_movie_data(url):\n",
    "    \"\"\"\n",
    "    Scrapes key box office data from the AndhraBoxOffice info page.\n",
    "    Returns a dictionary of the extracted data.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"movie_name\": \"N/A\",\n",
    "        \"total_WW_cls\": \"N/A\",\n",
    "        \"hero_name\": \"N/A\",\n",
    "        \"verdict\": \"N/A\",\n",
    "        \"day1_in_cr\": \"N/A\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # --- 1. Basic Info (Movie Name, Hero Name, Verdict) ---\n",
    "        \n",
    "        # Movie Name (from <h1> tag)\n",
    "        h1 = soup.find('h1')\n",
    "        if h1:\n",
    "            # Cleans up text like \"Dhruva Final Total WW Collections\" -> \"Dhruva\"\n",
    "            match = re.search(r'(.+?)\\s(Final Total WW Collections|Collections)', h1.text.strip())\n",
    "            data[\"movie_name\"] = match.group(1).strip() if match else h1.text.strip()\n",
    "        \n",
    "        # Hero Name (lbl_cast_name)\n",
    "        hero_span = soup.find('span', id=re.compile(r'lbl_cast_name'))\n",
    "        if hero_span:\n",
    "            cast_list = hero_span.text.strip()\n",
    "            # Assumes the first name is the main hero/star\n",
    "            data[\"hero_name\"] = cast_list.split(',')[0].strip() if ',' in cast_list else cast_list\n",
    "\n",
    "        # Verdict (lbl_verdict)\n",
    "        verdict_span = soup.find('span', id=re.compile(r'lbl_verdict'))\n",
    "        if verdict_span:\n",
    "            data[\"verdict\"] = verdict_span.text.strip()\n",
    "\n",
    "        # --- 2. Collection Data (Total WW Share, Day 1 Share) ---\n",
    "        \n",
    "        # Collection numbers are in a table structure, usually label/value in <td>s.\n",
    "        all_tds = soup.find_all('td')\n",
    "        for td in all_tds:\n",
    "            text = td.text.strip()\n",
    "            \n",
    "            # total_WW_cls (Worldwide Closing Share)\n",
    "            if 'Worldwide Closing Share' in text and data['total_WW_cls'] == 'N/A':\n",
    "                # The value is in the next sibling <td>\n",
    "                value_td = td.find_next_sibling('td')\n",
    "                if value_td:\n",
    "                    data['total_WW_cls'] = value_td.text.strip()\n",
    "            \n",
    "            # day1_in_cr (Day 1 Share)\n",
    "            if 'Day 1 Share' in text and data['day1_in_cr'] == 'N/A':\n",
    "                value_td = td.find_next_sibling('td')\n",
    "                if value_td:\n",
    "                    data['day1_in_cr'] = value_td.text.strip()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "def format_to_csv_string(data_dict):\n",
    "    \"\"\"\n",
    "    Formats the extracted dictionary data into a CSV string.\n",
    "    \"\"\"\n",
    "    if not data_dict:\n",
    "        return \"\"\n",
    "\n",
    "    # Define the order of columns for the CSV\n",
    "    fieldnames = ['movie_name', 'total_WW_cls', 'hero_name', 'verdict', 'day1_in_cr']\n",
    "    \n",
    "    # Use StringIO to capture the CSV output in memory\n",
    "    output = StringIO()\n",
    "    writer = csv.DictWriter(output, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "    # Write data row\n",
    "    writer.writerow(data_dict)\n",
    "\n",
    "    return output.getvalue()\n",
    "\n",
    "# --- RUN SCRAPER ---\n",
    "url = \"http://andhraboxoffice.com/info.aspx?id=2000&cid=6&fid=4540\"\n",
    "extracted_data = scrape_movie_data(url)\n",
    "\n",
    "# Format the extracted data into a CSV string\n",
    "csv_output = format_to_csv_string(extracted_data)\n",
    "\n",
    "print(csv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c174c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  movie_name total_WW_cls hero_name verdict day1_in_cr\n",
      "0    Unknown           NA        NA      NA         NA\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "def scrape_andhra_boxoffice(url):\n",
    "    r = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # ---------------- MOVIE NAME ----------------\n",
    "    try:\n",
    "        movie_name = soup.find(\"span\", id=\"lblMovieName\").text.strip()\n",
    "    except:\n",
    "        movie_name = \"Unknown\"\n",
    "\n",
    "    hero_name = \"NA\"\n",
    "    verdict = \"NA\"\n",
    "    total_ww = \"NA\"\n",
    "    day1 = \"NA\"\n",
    "\n",
    "    # ---------------- INFO TABLE ----------------\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    for table in tables:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "\n",
    "            if len(cols) < 2:\n",
    "                continue\n",
    "\n",
    "            label = cols[0].lower()\n",
    "            value = cols[1]\n",
    "\n",
    "            if \"hero\" in label:\n",
    "                hero_name = value\n",
    "\n",
    "            elif \"verdict\" in label:\n",
    "                verdict = value\n",
    "\n",
    "            elif \"world wide\" in label:\n",
    "                total_ww = value.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "            elif \"first day\" in label:\n",
    "                day1 = value.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "    # ---------------- FINAL STRUCTURE ----------------\n",
    "    data = {\n",
    "        \"movie_name\": movie_name,\n",
    "        \"total_WW_cls\": total_ww,\n",
    "        \"hero_name\": hero_name,\n",
    "        \"verdict\": verdict,\n",
    "        \"day1_in_cr\": day1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "url = \"http://andhraboxoffice.com/info.aspx?id=2000&cid=6&fid=4540\"\n",
    "\n",
    "df = scrape_andhra_boxoffice(url)\n",
    "\n",
    "df.to_csv(\"andhra_boxoffice_movie.csv\", index=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67db138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 437/2500 [12:03<56:55,  1.66s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     69\u001b[0m         movies\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m---> 70\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# VERY IMPORTANT (avoid ban)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(movies)\n\u001b[0;32m     74\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mandhra_boxoffice_bulk.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "def scrape_movie(movie_id, cid=6):\n",
    "    url = f\"http://andhraboxoffice.com/info.aspx?id={movie_id}&cid={cid}\"\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "        # ---------- MOVIE NAME ----------\n",
    "        try:\n",
    "            movie_name = soup.find(\"span\", id=\"lblMovieName\").text.strip()\n",
    "        except:\n",
    "            return None   # invalid movie page\n",
    "\n",
    "        hero = verdict = ww = day1 = \"NA\"\n",
    "\n",
    "        # ---------- INFO TABLE ----------\n",
    "        for table in soup.find_all(\"table\"):\n",
    "            for row in table.find_all(\"tr\"):\n",
    "                cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "                if len(cols) < 2:\n",
    "                    continue\n",
    "\n",
    "                key = cols[0].lower()\n",
    "                val = cols[1]\n",
    "\n",
    "                if \"hero\" in key:\n",
    "                    hero = val\n",
    "                elif \"verdict\" in key:\n",
    "                    verdict = val\n",
    "                elif \"world wide\" in key:\n",
    "                    ww = val.replace(\"Cr\", \"\").strip()\n",
    "                elif \"first day\" in key:\n",
    "                    day1 = val.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "        return {\n",
    "            \"movie_id\": movie_id,\n",
    "            \"movie_name\": movie_name,\n",
    "            \"hero_name\": hero,\n",
    "            \"verdict\": verdict,\n",
    "            \"total_WW_cls\": ww,\n",
    "            \"day1_in_cr\": day1\n",
    "        }\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- BULK RUN ----------------\n",
    "movies = []\n",
    "START_ID = 1\n",
    "END_ID = 2500   # you can increase later\n",
    "\n",
    "for movie_id in tqdm(range(START_ID, END_ID + 1)):\n",
    "    data = scrape_movie(movie_id)\n",
    "    if data:\n",
    "        movies.append(data)\n",
    "    time.sleep(1.5)   # VERY IMPORTANT (avoid ban)\n",
    "\n",
    "df = pd.DataFrame(movies)\n",
    "\n",
    "df.to_csv(\"andhra_boxoffice_bulk.csv\", index=False)\n",
    "print(\"Saved:\", len(df), \"movies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0329ac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 366/2599 [09:59<1:00:56,  1.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     72\u001b[0m         movies\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m---> 73\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(movies)\n\u001b[0;32m     76\u001b[0m df_movies\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop6_heroes_movies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "TOP_HEROES = [\n",
    "    \"Mahesh Babu\",\n",
    "    \"Pawan Kalyan\",\n",
    "    \"Prabhas\",\n",
    "    \"Allu Arjun\",\n",
    "    \"Jr NTR\",\n",
    "    \"Ram Charan\"\n",
    "]\n",
    "\n",
    "def scrape_movie(movie_id):\n",
    "    url = f\"http://andhraboxoffice.com/info.aspx?id={movie_id}&cid=6\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "        movie_name = soup.find(\"span\", id=\"lblMovieName\").text.strip()\n",
    "\n",
    "        hero = verdict = ww = day1 = \"NA\"\n",
    "\n",
    "        for table in soup.find_all(\"table\"):\n",
    "            for row in table.find_all(\"tr\"):\n",
    "                cols = [c.text.strip() for c in row.find_all(\"td\")]\n",
    "                if len(cols) < 2:\n",
    "                    continue\n",
    "\n",
    "                key = cols[0].lower()\n",
    "                val = cols[1]\n",
    "\n",
    "                if \"hero\" in key:\n",
    "                    hero = val\n",
    "                elif \"verdict\" in key:\n",
    "                    verdict = val\n",
    "                elif \"world wide\" in key:\n",
    "                    ww = val.replace(\"Cr\", \"\").strip()\n",
    "                elif \"first day\" in key:\n",
    "                    day1 = val.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "        if hero not in TOP_HEROES:\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            \"movie_id\": movie_id,\n",
    "            \"movie_name\": movie_name,\n",
    "            \"hero_name\": hero,\n",
    "            \"day1_in_cr\": day1,\n",
    "            \"total_WW_cls\": ww,\n",
    "            \"verdict\": verdict\n",
    "        }\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# -------- BULK RUN --------\n",
    "movies = []\n",
    "\n",
    "for mid in tqdm(range(1, 2600)):\n",
    "    data = scrape_movie(mid)\n",
    "    if data:\n",
    "        movies.append(data)\n",
    "    time.sleep(1.5)\n",
    "\n",
    "df_movies = pd.DataFrame(movies)\n",
    "df_movies.to_csv(\"top6_heroes_movies.csv\", index=False)\n",
    "\n",
    "print(\"Movies scraped:\", len(df_movies))\n",
    "def clean_number(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_movies[\"day1_in_cr\"] = df_movies[\"day1_in_cr\"].apply(clean_number)\n",
    "df_movies[\"total_WW_cls\"] = df_movies[\"total_WW_cls\"].apply(clean_number)\n",
    "def is_hit(verdict):\n",
    "    verdict = str(verdict).lower()\n",
    "    return any(x in verdict for x in [\"hit\", \"blockbuster\", \"super hit\", \"industry hit\"])\n",
    "\n",
    "career = df_movies.groupby(\"hero_name\").agg(\n",
    "    total_movies=(\"movie_name\", \"count\"),\n",
    "    hits=(\"verdict\", lambda x: sum(is_hit(v) for v in x)),\n",
    "    avg_day1=(\"day1_in_cr\", \"mean\"),\n",
    "    total_ww=(\"total_WW_cls\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "career[\"flops\"] = career[\"total_movies\"] - career[\"hits\"]\n",
    "\n",
    "career.to_csv(\"top6_heroes_career_summary.csv\", index=False)\n",
    "print(career)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da990d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Baahubali 2 The Conclusion\n",
      "Day 1: N/A Cr | Total: 1700 Cr\n",
      "Scraping: Pushpa 2 The Rule\n",
      "Day 1: N/A Cr | Total: 200 Cr\n",
      "Scraping: Kalki 2898 AD\n",
      "Day 1: N/A Cr | Total: 200 Cr\n",
      "Scraping: RRR\n",
      "Day 1: 6 Cr | Total: 200 Cr\n",
      "Scraping: Salaar\n",
      "Day 1: N/A Cr | Total: 200 Cr\n",
      "Scraping: Dhurva\n",
      "Day 1: N/A Cr | Total: 200 Cr\n",
      "Scraping: Saaho\n",
      "Day 1: N/A Cr | Total: 200 Cr\n",
      "\n",
      "✅ Saved to specific_movie_data.csv\n",
      "                   movie_name total_WW_cls      verdict day1_WW_Gross_cr\n",
      "0  Baahubali 2 The Conclusion         1700  Blockbuster              N/A\n",
      "1           Pushpa 2 The Rule          200  Blockbuster              N/A\n",
      "2               Kalki 2898 AD          200  Blockbuster              N/A\n",
      "3                         RRR          200  Blockbuster                6\n",
      "4                      Salaar          200  Blockbuster              N/A\n",
      "5                      Dhurva          200  Blockbuster              N/A\n",
      "6                       Saaho          200          Hit              N/A\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_specific_movie(movie_name, hero_name=None):\n",
    "    \"\"\"\n",
    "    Scrape box office data for a SPECIFIC Telugu movie from multiple sources\n",
    "    Returns: movie_name, day1_WW, total_WW, verdict\n",
    "    \"\"\"\n",
    "    \n",
    "    # Priority sources for Telugu movies (most reliable)\n",
    "    sources = [\n",
    "        f\"https://www.sacnilk.com/news/{movie_name.replace(' ', '_').lower()}_box_office_collection_day_wise_worldwide\",\n",
    "        f\"https://www.koimoi.com/box-office/{movie_name.lower().replace(' ', '-')}_box_office_collection\",\n",
    "        f\"https://en.wikipedia.org/w/index.php?search={movie_name}+box+office+telugu\"\n",
    "    ]\n",
    "    \n",
    "    data = {'movie_name': movie_name, 'day1_WW': 'N/A', 'total_WW': 'N/A', 'verdict': 'N/A', 'source': 'None'}\n",
    "    \n",
    "    for url in sources:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Try Sacnilk/Koimoi patterns first (most reliable for Day 1)\n",
    "            day1_patterns = [\n",
    "                r'Day 1.*?₹?([\\d,.]+)\\s*cr',\n",
    "                r'Opening Day.*?₹?([\\d,.]+)\\s*cr',\n",
    "                r'1st Day.*?₹?([\\d,.]+).*?Worldwide'\n",
    "            ]\n",
    "            \n",
    "            total_patterns = [\n",
    "                r'Worldwide.*?₹?([\\d,.]+)\\s*cr',\n",
    "                r'Total.*?₹?([\\d,.]+)\\s*cr',\n",
    "                r'Final.*?₹?([\\d,.]+)\\s*cr'\n",
    "            ]\n",
    "            \n",
    "            text = soup.get_text()\n",
    "            \n",
    "            # Extract Day 1\n",
    "            for pattern in day1_patterns:\n",
    "                match = re.search(pattern, text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    data['day1_WW'] = match.group(1).replace(',', '')\n",
    "                    data['source'] = url\n",
    "                    break\n",
    "            \n",
    "            # Extract Total WW\n",
    "            for pattern in total_patterns:\n",
    "                match = re.search(pattern, text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    data['total_WW'] = match.group(1).replace(',', '')\n",
    "                    break\n",
    "            \n",
    "            # Extract Verdict\n",
    "            verdict_patterns = [r'\\b(Super Hit|Blockbuster|Hit|Flop|Disaster|Average)\\b']\n",
    "            for pattern in verdict_patterns:\n",
    "                match = re.search(pattern, text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    data['verdict'] = match.group(1).title()\n",
    "                    break\n",
    "            \n",
    "            if data['day1_WW'] != 'N/A':\n",
    "                break  # Found data, stop searching\n",
    "                \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    time.sleep(1)  # Rate limit\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    # Test with specific movies from your list\n",
    "    movies_to_scrape = [\n",
    "        'Baahubali 2 The Conclusion',\n",
    "        'Pushpa 2 The Rule', \n",
    "        'Kalki 2898 AD',\n",
    "        'RRR',\n",
    "        'Salaar',\n",
    "        'Dhurva',\n",
    "        'Saaho'\n",
    "    ]\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for movie in movies_to_scrape:\n",
    "        print(f\"Scraping: {movie}\")\n",
    "        result = scrape_specific_movie(movie)\n",
    "        all_data.append(result)\n",
    "        print(f\"Day 1: {result['day1_WW']} Cr | Total: {result['total_WW']} Cr\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Save to CSV (your exact format)\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df[['movie_name', 'total_WW', 'verdict', 'day1_WW']]\n",
    "    df.columns = ['movie_name', 'total_WW_cls', 'verdict', 'day1_WW_Gross_cr']\n",
    "    \n",
    "    df.to_csv('specific_movie_data.csv', index=False)\n",
    "    print(\"\\n✅ Saved to specific_movie_data.csv\")\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca322a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Dhruva\n",
      "{'movie_name': 'Dhruva', 'hero_name': 'Unknown', 'verdict': 'Unknown', 'total_WW_cls': '', 'day1_in_cr': 'N/A', 'area_data': {'Previous\\nNext\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNEWS\\n\\n\\n\\n\\n\\nGALLERY\\n\\n\\n\\n\\n\\nTRADE\\n\\n\\n\\n\\n\\nCOLLECTIONS\\n\\n\\n\\n\\n\\nCENTRES\\n\\n\\n\\n\\n\\nREVIEWS\\n\\n\\n\\n\\n\\nVIDEOS\\n\\n\\n\\n\\n\\n\\n\\n\\nFORUM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n            \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Collections\\r\\n            \\n\\n\\n\\n01/09/2017\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShareOnFB \\n\\n\\n\\n\\nTweet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 10 Days Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Week Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Weekend Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 5 Days Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Day Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome |\\nDisclaimer |\\n\\r\\n                                                        Contact Us\\nCopyright © 2010 \\r\\n                                                        andhraboxoffice.com. All rights reserved.': '', '': '', 'NEWS\\n\\n\\n\\n\\n\\nGALLERY\\n\\n\\n\\n\\n\\nTRADE\\n\\n\\n\\n\\n\\nCOLLECTIONS\\n\\n\\n\\n\\n\\nCENTRES\\n\\n\\n\\n\\n\\nREVIEWS\\n\\n\\n\\n\\n\\nVIDEOS\\n\\n\\n\\n\\n\\n\\n\\n\\nFORUM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n            \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Collections\\r\\n            \\n\\n\\n\\n01/09/2017\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShareOnFB \\n\\n\\n\\n\\nTweet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 10 Days Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Week Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Weekend Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 5 Days Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Day Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome |\\nDisclaimer |\\n\\r\\n                                                        Contact Us\\nCopyright © 2010 \\r\\n                                                        andhraboxoffice.com. All rights reserved.': 'NEWS\\n\\n\\n\\n\\n\\nGALLERY\\n\\n\\n\\n\\n\\nTRADE\\n\\n\\n\\n\\n\\nCOLLECTIONS\\n\\n\\n\\n\\n\\nCENTRES\\n\\n\\n\\n\\n\\nREVIEWS\\n\\n\\n\\n\\n\\nVIDEOS\\n\\n\\n\\n\\n\\n\\n\\n\\nFORUM', 'NEWS\\n\\n\\n\\n\\n\\nGALLERY\\n\\n\\n\\n\\n\\nTRADE\\n\\n\\n\\n\\n\\nCOLLECTIONS\\n\\n\\n\\n\\n\\nCENTRES\\n\\n\\n\\n\\n\\nREVIEWS\\n\\n\\n\\n\\n\\nVIDEOS\\n\\n\\n\\n\\n\\n\\n\\n\\nFORUM': '', 'Collections\\r\\n            \\n\\n\\n\\n01/09/2017\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShareOnFB \\n\\n\\n\\n\\nTweet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 10 Days Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Week Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Weekend Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 5 Days Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Day Total WW Collections': '', 'ShareOnFB \\n\\n\\n\\n\\nTweet': 'ShareOnFB', 'ShareOnFB': '', 'Dhruva Final Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 10 Days Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Week Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Weekend Total WW Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 5 Days Collections\\n\\n\\n\\n\\n\\n\\n\\n\\nDhruva 1st Day Total WW Collections': 'Dhruva Final Total WW Collections', 'Dhruva Final Total WW Collections': '', 'Dhruva 10 Days Total WW Collections': '', 'Dhruva 1st Week Total WW Collections': '', 'Dhruva 1st Weekend Total WW Collections': '', 'Dhruva 5 Days Collections': '', 'Dhruva 1st Day Total WW Collections': '', 'Contact Us......': '', 'For Advertising and Queries Contact Us @:': '', 'info@andhraboxoffice.com': ''}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def scrape_andhraboxoffice(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=10)\n",
    "        r.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return {\"error\": \"Failed to fetch page\"}\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    # Movie name - from title tag, clean it\n",
    "    try:\n",
    "        title_text = soup.find(\"title\").text.strip()\n",
    "        movie_name = re.sub(r\" Final Total WW Collections.*\", \"\", title_text).strip()\n",
    "    except:\n",
    "        movie_name = \"Unknown\"\n",
    "    print(f\"Scraping: {movie_name}\")\n",
    "    \n",
    "    # Hero name - search for common patterns, e.g., in meta or text\n",
    "    hero_name = \"Unknown\"\n",
    "    page_text = soup.get_text().lower()\n",
    "    possible_heroes = [\"ram charan\", \"chiranjeevi\", \"pawan kalyan\", \"mahesh babu\", \"prabhas\"]  # Add more as needed\n",
    "    for hero in possible_heroes:\n",
    "        if hero in page_text:\n",
    "            hero_name = hero.capitalize()\n",
    "            break\n",
    "    # Alternatively, if structured, e.g., find span or div with cast\n",
    "    \n",
    "    # Verdict - search for \"Verdict :\" or similar\n",
    "    verdict = \"Unknown\"\n",
    "    verdict_match = re.search(r\"Verdict\\s*:\\s*([^\\n]+)\", soup.get_text(), re.IGNORECASE)\n",
    "    if verdict_match:\n",
    "        verdict = verdict_match.group(1).strip()\n",
    "    \n",
    "    # Collections - find table(s)\n",
    "    total_ww_cls = \"N/A\"\n",
    "    day1_in_cr = \"N/A\"  # Day 1 might not be on final page; assume from text or separate\n",
    "    area_data = {}\n",
    "    \n",
    "    tables = soup.find_all(\"table\")\n",
    "    if tables:\n",
    "        for table in tables:\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cols = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "                if len(cols) >= 2:\n",
    "                    area = cols[0].strip()\n",
    "                    value = cols[1].strip()\n",
    "                    area_data[area] = value\n",
    "                    if \"worldwide\" in area.lower() or \"total ww\" in area.lower():\n",
    "                        total_ww_cls = value\n",
    "                    if \"day 1\" in area.lower() or \"opening day\" in area.lower():\n",
    "                        day1_in_cr = value\n",
    "    \n",
    "    # If no explicit day1, perhaps estimate or note absence\n",
    "    if day1_in_cr == \"N/A\" and \"day1\" in page_text.lower():\n",
    "        # More advanced parsing if needed\n",
    "        day1_match = re.search(r\"Day 1\\s*:\\s*([\\d.]+)\\s*Cr\", soup.get_text(), re.IGNORECASE)\n",
    "        if day1_match:\n",
    "            day1_in_cr = day1_match.group(1) + \" Cr\"\n",
    "    \n",
    "    return {\n",
    "        \"movie_name\": movie_name,\n",
    "        \"hero_name\": hero_name,\n",
    "        \"verdict\": verdict,\n",
    "        \"total_WW_cls\": total_ww_cls,\n",
    "        \"day1_in_cr\": day1_in_cr,\n",
    "        \"area_data\": area_data  # Extra for robustness\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "url = \"http://andhraboxoffice.com/info.aspx?id=2000&cid=6&fid=4540\"\n",
    "data = scrape_andhraboxoffice(url)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685abb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Name : Dhruva Final Total WW Collections| AndhraBoxOffice.com\n",
      "Hero       : NA\n",
      "Verdict    : NA\n",
      "Day 1 (Cr) : NA\n",
      "WW Total   : NA\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://andhraboxoffice.com/info.aspx?id=2000&cid=6&fid=4540\"\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "r = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# ---------------- MOVIE NAME (SAFE) ----------------\n",
    "movie_name = \"Unknown Movie\"\n",
    "\n",
    "# try 1\n",
    "span = soup.find(\"span\", id=\"lblMovieName\")\n",
    "if span:\n",
    "    movie_name = span.text.strip()\n",
    "else:\n",
    "    # try 2 (fallback)\n",
    "    h1 = soup.find(\"h1\")\n",
    "    if h1:\n",
    "        movie_name = h1.text.strip()\n",
    "    else:\n",
    "        # try 3 (last fallback)\n",
    "        movie_name = soup.title.text.strip()\n",
    "\n",
    "# ---------------- DEFAULT VALUES ----------------\n",
    "hero_name = \"NA\"\n",
    "verdict = \"NA\"\n",
    "total_ww = \"NA\"\n",
    "day1 = \"NA\"\n",
    "\n",
    "# ---------------- SCRAPE TABLE DATA ----------------\n",
    "for table in soup.find_all(\"table\"):\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cols = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "\n",
    "        if len(cols) < 2:\n",
    "            continue\n",
    "\n",
    "        label = cols[0].lower()\n",
    "        value = cols[1]\n",
    "\n",
    "        if \"hero\" in label:\n",
    "            hero_name = value\n",
    "\n",
    "        elif \"verdict\" in label:\n",
    "            verdict = value\n",
    "\n",
    "        elif \"world wide\" in label:\n",
    "            total_ww = value.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "        elif \"first day\" in label:\n",
    "            day1 = value.replace(\"Cr\", \"\").strip()\n",
    "\n",
    "# ---------------- RESULT ----------------\n",
    "print(\"Movie Name :\", movie_name)\n",
    "print(\"Hero       :\", hero_name)\n",
    "print(\"Verdict    :\", verdict)\n",
    "print(\"Day 1 (Cr) :\", day1)\n",
    "print(\"WW Total   :\", total_ww)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd0a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad9b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
