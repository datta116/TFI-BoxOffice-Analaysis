{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13699cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 movies: ['Adipurush_raw.csv', 'agv_raw.csv', 'asvr_raw.csv', 'BAN_raw.csv', 'BN_raw.csv', 'BRO_raw.csv', 'D2_raw.csv', 'Dasara_raw.csv', 'DC_raw.CSV', 'devara_raw.csv', 'dhruva_raw.csv', 'dj_raw.csv', 'Eagle_raw.csv', 'F3_raw.csv', 'GG_raw.CSV', 'GK_raw.csv', 'HN_raw.CSV', 'JG_raw.csv', 'Kalki2898AD_raw.csv', 'kushi_raw.csv', 'liger_raw.csv', 'Maharshi_raw.csv', 'NPS_raw.csv', 'nsni_raw.csv', 'OG_raw.csv', 'RadheyShyam_raw.csv', 'Ravanasura_raw.csv', 'rgs_raw.csv', 'RRR_raw.csv', 'Saaho_raw.csv', 'saindav_raw.csv', 'Salaar_raw.csv', 'SK_raw.csv', 'SLN_raw.csv', 'SSR_raw.csv', 'SVP_raw.csv', 'TJ_raw.csv', 'TNR_raw.csv', 'VK_raw.csv', 'WAR2_raw.csv', 'wfl_raw.csv']\n",
      "Processing (1/41): Adipurush_raw.csv\n",
      "Processing (2/41): agv_raw.csv\n",
      "Processing (3/41): asvr_raw.csv\n",
      "Processing (4/41): BAN_raw.csv\n",
      "Processing (5/41): BN_raw.csv\n",
      "Processing (6/41): BRO_raw.csv\n",
      "Processing (7/41): D2_raw.csv\n",
      "Processing (8/41): Dasara_raw.csv\n",
      "Processing (9/41): DC_raw.CSV\n",
      "Processing (10/41): devara_raw.csv\n",
      "Processing (11/41): dhruva_raw.csv\n",
      "Processing (12/41): dj_raw.csv\n",
      "Processing (13/41): Eagle_raw.csv\n",
      "Processing (14/41): F3_raw.csv\n",
      "Processing (15/41): GG_raw.CSV\n",
      "Processing (16/41): GK_raw.csv\n",
      "Processing (17/41): HN_raw.CSV\n",
      "Processing (18/41): JG_raw.csv\n",
      "Processing (19/41): Kalki2898AD_raw.csv\n",
      "Processing (20/41): kushi_raw.csv\n",
      "Processing (21/41): liger_raw.csv\n",
      "Processing (22/41): Maharshi_raw.csv\n",
      "Processing (23/41): NPS_raw.csv\n",
      "Processing (24/41): nsni_raw.csv\n",
      "Processing (25/41): OG_raw.csv\n",
      "Processing (26/41): RadheyShyam_raw.csv\n",
      "Processing (27/41): Ravanasura_raw.csv\n",
      "Processing (28/41): rgs_raw.csv\n",
      "Processing (29/41): RRR_raw.csv\n",
      "Processing (30/41): Saaho_raw.csv\n",
      "Processing (31/41): saindav_raw.csv\n",
      "Processing (32/41): Salaar_raw.csv\n",
      "Processing (33/41): SK_raw.csv\n",
      "Processing (34/41): SLN_raw.csv\n",
      "Processing (35/41): SSR_raw.csv\n",
      "Processing (36/41): SVP_raw.csv\n",
      "Processing (37/41): TJ_raw.csv\n",
      "Processing (38/41): TNR_raw.csv\n",
      "Processing (39/41): VK_raw.csv\n",
      "Processing (40/41): WAR2_raw.csv\n",
      "Processing (41/41): wfl_raw.csv\n",
      "\n",
      "SUCCESS! ALL MOVIES COMBINED\n",
      "Total rows: 537\n",
      "Total movies: 39\n",
      "Unique movie_ids: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41]\n",
      "\n",
      "Files saved:\n",
      "   TFI_MASTER_DATASET.csv\n",
      "   TFI_MASTER_DATASET.xlsx  ← Open in Power BI!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "files = glob.glob(\"*_raw.csv\")\n",
    "\n",
    "if not files:\n",
    "    print(\"No *_raw.csv files found!\")\n",
    "else:\n",
    "    print(f\"Found {len(files)} movies: {files}\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, file in enumerate(files, start=1):  # movie_id starts from 1\n",
    "    print(f\"Processing ({i}/{len(files)}): {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "    raw_name = os.path.splitext(file)[0].replace(\"_raw\", \"\")\n",
    "    if 'movie_name' in df.columns and df['movie_name'].notna().any():\n",
    "        movie_name = df['movie_name'].iloc[0].split(\" Box Office\")[0].strip()\n",
    "    else:\n",
    "        movie_name = raw_name\n",
    "\n",
    "    df[\"movie\"] = movie_name\n",
    "    df[\"movie_id\"] = i  # Unique ID: 1,2,3,...\n",
    "\n",
    "    if 'day' in df.columns:\n",
    "        df[\"primary_key\"] = df[\"movie\"] + \" | \" + df[\"day\"].astype(str)\n",
    "    else:\n",
    "        df[\"primary_key\"] = df[\"movie\"] + \" | Row_\" + df.index.astype(str)\n",
    "\n",
    "\n",
    "    desired_cols = [\n",
    "        \"movie_id\", \"movie\", \"day\", \"india_net\", \"change_percent\",\n",
    "        \"karnataka\", \"aptg\", \"tamil_nadu\", \"kerala\", \"rest_of_india\", \"day_total\",\n",
    "        \"budget\", \"verdict\", \"india_screens\", \"overseas_screens\",\n",
    "        \"worldwide_screens\", \"release_date\", \"primary_key\"\n",
    "    ]\n",
    "    df = df[[col for col in desired_cols if col in df.columns]]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df.drop_duplicates(subset=[\"primary_key\"], keep=\"first\", inplace=True)\n",
    "\n",
    "combined_df[\"day_num\"] = combined_df[\"day\"].str.extract(r'(\\d+)').astype(float).fillna(999)\n",
    "combined_df = combined_df.sort_values([\"movie_id\", \"day_num\"]).drop(columns=[\"day_num\"], errors=\"ignore\")\n",
    "\n",
    "# Final cleanup\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ------------------- SAVE FINAL FILES -------------------\n",
    "combined_df.to_csv(\"TFI_MASTER_DATASET.csv\", index=False)\n",
    "combined_df.to_excel(\"TFI_MASTER_DATASET.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nSUCCESS! ALL MOVIES COMBINED\")\n",
    "print(f\"Total rows: {len(combined_df):,}\")\n",
    "print(f\"Total movies: {combined_df['movie'].nunique()}\")\n",
    "print(f\"Unique movie_ids: {sorted(combined_df['movie_id'].unique())}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"   TFI_MASTER_DATASET.csv\")\n",
    "print(\"   TFI_MASTER_DATASET.xlsx  ← Open in Power BI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf85639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Now every movie has its hero.\n",
      "     movie_id                           movie        hero\n",
      "0           1                       Adipurush     Prabhas\n",
      "20          2                  Agnyaathavaasi     Prabhas\n",
      "28          3  Aravinda Sametha Veera Raghava     Prabhas\n",
      "33          4                 Bharat Ane Nenu     Prabhas\n",
      "38          5                   Bheemla Nayak     Prabhas\n",
      "55          6                             Bro      Jr NTR\n",
      "69          7                      Drushyam 2      Jr NTR\n",
      "74          8                          Dasara      Jr NTR\n",
      "79          9                    Dear Comrade      Jr NTR\n",
      "84         10                 Devara - Part 1      Jr NTR\n",
      "125        11                          Dhruva  Ram Charan\n",
      "131        12             Duvvada Jagannadham  Ram Charan\n",
      "136        13                           Eagle  Ram Charan\n",
      "141        14         F3: Fun and Frustration  Ram Charan\n",
      "146        15                 Geetha Govindam  Ram Charan\n",
      "151        16                   Guntur Kaaram         NaN\n",
      "176        17                        Hi Nanna         NaN\n",
      "181        18                  Janatha Garage         NaN\n",
      "185        19                   Kalki 2898 AD         NaN\n",
      "227        20                           Kushi         NaN\n",
      "232        21                           Liger         NaN\n",
      "237        22                        Maharshi         NaN\n",
      "269        24   Naa Peru Surya Naa Illu India         NaN\n",
      "275        25                They Call Him OG         NaN\n",
      "298        26                     Radhe Shyam         NaN\n",
      "307        27                      Ravanasura         NaN\n",
      "312        28                    Rangasthalam         NaN\n",
      "319        29                             RRR         NaN\n",
      "361        30                           Saaho         NaN\n",
      "388        31                        Saindhav         NaN\n",
      "393        32                          Salaar         NaN\n",
      "435        33          Sankranthiki Vasthunam         NaN\n",
      "440        35                Shyam Singha Roy         NaN\n",
      "445        36             Sarkaru Vaari Paata         NaN\n",
      "463        37                   Tuck Jagadish         NaN\n",
      "468        38             Tiger Nageswara Rao         NaN\n",
      "473        39                     Vakeel Saab         NaN\n",
      "490        40                           War 2         NaN\n",
      "532        41              World Famous Lover         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"TFI_MASTER_DATASET.csv\")\n",
    "\n",
    "# Mapping dictionary (add more when you add movies)\n",
    "hero_map = {\n",
    "    1: \"Prabhas\", 2: \"Prabhas\", 3: \"Prabhas\", 4: \"Prabhas\", 5: \"Prabhas\",\n",
    "    6: \"Jr NTR\",   7: \"Jr NTR\",   8: \"Jr NTR\",   9: \"Jr NTR\",   10: \"Jr NTR\",\n",
    "    11: \"Ram Charan\", 12: \"Ram Charan\", 13: \"Ram Charan\", 14: \"Ram Charan\", 15: \"Ram Charan\",\n",
    "    # add next heroes here\n",
    "}\n",
    "\n",
    "df[\"hero\"] = df[\"movie_id\"].map(hero_map)\n",
    "\n",
    "df.to_csv(\"TFI_MASTER_WITH_HERO.csv\", index=False)\n",
    "df.to_excel(\"TFI_MASTER_WITH_HERO.xlsx\", index=False)\n",
    "\n",
    "print(\"Done! Now every movie has its hero.\")\n",
    "print(df[[\"movie_id\", \"movie\", \"hero\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8ae349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 737 rows, 48 movies\n",
      "\n",
      "CLEANING + HERO MAPPING DONE!\n",
      "Hero breakdown:\n",
      "hero\n",
      "Prabhas              140\n",
      "Allu Arjun           136\n",
      "Mahesh Babu           99\n",
      "Jr NTR                92\n",
      "Pawan Kalyan          79\n",
      "Ram Charan            55\n",
      "Jr NTR/Ram Charan     42\n",
      "Ravi Teja             25\n",
      "Nani                  25\n",
      "Vijay Deverakonda     25\n",
      "Venkatesh             19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "   movie_id     hero      movie                    day  india_net\n",
      "0         1  Prabhas  Adipurush     Day 1 [1st Friday]      13.70\n",
      "1         1  Prabhas  Adipurush           Week 1 Share      34.00\n",
      "2         1  Prabhas  Adipurush   Day 2 [1st Saturday]       7.78\n",
      "3         1  Prabhas  Adipurush           Week 2 Share       2.31\n",
      "4         1  Prabhas  Adipurush     Day 3 [1st Sunday]       8.15\n",
      "5         1  Prabhas  Adipurush     Day 4 [1st Monday]       2.15\n",
      "6         1  Prabhas  Adipurush    Day 5 [1st Tuesday]       1.22\n",
      "7         1  Prabhas  Adipurush  Day 6 [1st Wednesday]       0.62\n",
      "8         1  Prabhas  Adipurush   Day 7 [1st Thursday]       0.38\n",
      "9         1  Prabhas  Adipurush     Day 8 [2nd Friday]       0.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your master file\n",
    "df = pd.read_csv(\"Master.csv\")\n",
    "print(f\"Loaded {len(df)} rows, {df['movie'].nunique()} movies\")\n",
    "\n",
    "# 1. Clean money columns\n",
    "money_cols = ['india_net', 'day_total', 'karnataka', 'aptg',\n",
    "              'tamil_nadu', 'kerala', 'rest_of_india']\n",
    "for col in money_cols:\n",
    "    df[col] = df[col].astype(str).str.extract(r'([\\d\\.]+)').astype(float)\n",
    "\n",
    "# 2. Clean movie name\n",
    "df['movie'] = df['movie'].str.split(' Box Office').str[0].str.strip()\n",
    "\n",
    "# 3. Clean release_date\n",
    "df['release_date'] = df['release_date'].astype(str).str.extract(r'(\\d{1,2}\\w{2} \\w+ \\d{4})')\n",
    "\n",
    "# FULL HERO MAPPING — ALL YOUR CURRENT & FUTURE HEROES\n",
    "hero_dict = {\n",
    "    1: \"Prabhas\", 22: \"Prabhas\", 33: \"Prabhas\", 37: \"Prabhas\", 39: \"Prabhas\",\n",
    "\n",
    "4: \"Allu Arjun\", 14: \"Allu Arjun\", 29: \"Allu Arjun\", 31: \"Allu Arjun\", 32: \"Allu Arjun\",\n",
    "\n",
    "13: \"Ram Charan\", 17: \"Ram Charan\", 35: \"Ram Charan\", 47: \"Ram Charan\", 36: \"Ram Charan/Jr.NTR\",\n",
    "\n",
    "3: \"Jr NTR\", 12: \"Jr NTR\", 21: \"Jr NTR\", 36: \"Jr NTR/Ram Charan\", 48: \"Jr NTR\",\n",
    "\n",
    "5: \"Mahesh Babu\", 19: \"Mahesh Babu\", 26: \"Mahesh Babu\", 41: \"Mahesh Babu\", 43: \"Mahesh Babu\",\n",
    "\n",
    "2: \"Pawan Kalyan\", 6: \"Pawan Kalyan\", 7: \"Pawan Kalyan\", 30: \"Pawan Kalyan\", 46: \"Pawan Kalyan\",\n",
    "\n",
    "11: \"Vijay Deverakonda\", 18: \"Vijay Deverakonda\", 24: \"Vijay Deverakonda\",\n",
    "25: \"Vijay Deverakonda\", 49: \"Vijay Deverakonda\",\n",
    "\n",
    "10: \"Nani\", 20: \"Nani\", 42: \"Nani\", 44: \"Nani\", 40: \"Nani\",\n",
    "\n",
    "9: \"Ravi Teja\", 15: \"Ravi Teja\", 23: \"Ravi Teja\", 34: \"Ravi Teja\", 45: \"Ravi Teja\",\n",
    "\n",
    "8: \"Venkatesh\", 16: \"Venkatesh\", 27: \"Venkatesh\", 38: \"Venkatesh\"}\n",
    "# Apply hero mapping\n",
    "df['hero'] = df['movie_id'].map(hero_dict)\n",
    "\n",
    "# Fill any missing heroes with \"Unknown\" (safety net)\n",
    "df['hero'] = df['hero'].fillna(\"Unknown\")\n",
    "\n",
    "# Reorder columns\n",
    "final_cols = ['movie_id','hero','movie','day','india_net','change_percent',\n",
    "              'karnataka','aptg','tamil_nadu','kerala','rest_of_india','day_total',\n",
    "              'budget','verdict','india_screens','overseas_screens',\n",
    "              'worldwide_screens','release_date','primary_key']\n",
    "df = df[final_cols]\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"Master_cleaned.csv\", index=False)\n",
    "df.to_excel(\"Master_cleaned.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nCLEANING + HERO MAPPING DONE!\")\n",
    "print(f\"Hero breakdown:\\n{df['hero'].value_counts()}\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df[['movie_id','hero','movie','day','india_net']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ba5bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>hero</th>\n",
       "      <th>movie</th>\n",
       "      <th>day</th>\n",
       "      <th>india_net</th>\n",
       "      <th>change_percent</th>\n",
       "      <th>karnataka</th>\n",
       "      <th>aptg</th>\n",
       "      <th>tamil_nadu</th>\n",
       "      <th>kerala</th>\n",
       "      <th>rest_of_india</th>\n",
       "      <th>day_total</th>\n",
       "      <th>budget</th>\n",
       "      <th>verdict</th>\n",
       "      <th>india_screens</th>\n",
       "      <th>overseas_screens</th>\n",
       "      <th>worldwide_screens</th>\n",
       "      <th>release_date</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 1 [1st Friday]</td>\n",
       "      <td>13.70</td>\n",
       "      <td>₹ 3.5 Cr</td>\n",
       "      <td>7.2</td>\n",
       "      <td>48.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>44.80</td>\n",
       "      <td>102.5</td>\n",
       "      <td>₹ 450 Cr * Approx</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 1 [1st Friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Week 1 Share</td>\n",
       "      <td>34.00</td>\n",
       "      <td>₹ 9.04 Cr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹ 450 Cr * Approx</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Week 1 Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 2 [1st Saturday]</td>\n",
       "      <td>7.78</td>\n",
       "      <td>₹ 1.75 Cr</td>\n",
       "      <td>5.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>44.25</td>\n",
       "      <td>77.0</td>\n",
       "      <td>₹ 450 Cr * Approx</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 2 [1st Saturday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Week 2 Share</td>\n",
       "      <td>2.31</td>\n",
       "      <td>₹ 0.89 Cr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹ 450 Cr * Approx</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Week 2 Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 3 [1st Sunday]</td>\n",
       "      <td>8.15</td>\n",
       "      <td>₹ 2.25 Cr</td>\n",
       "      <td>5.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>45.75</td>\n",
       "      <td>81.5</td>\n",
       "      <td>₹ 450 Cr * Approx</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 3 [1st Sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id     hero      movie                   day  india_net  \\\n",
       "0         1  Prabhas  Adipurush    Day 1 [1st Friday]      13.70   \n",
       "1         1  Prabhas  Adipurush          Week 1 Share      34.00   \n",
       "2         1  Prabhas  Adipurush  Day 2 [1st Saturday]       7.78   \n",
       "3         1  Prabhas  Adipurush          Week 2 Share       2.31   \n",
       "4         1  Prabhas  Adipurush    Day 3 [1st Sunday]       8.15   \n",
       "\n",
       "  change_percent  karnataka  aptg  tamil_nadu  kerala  rest_of_india  \\\n",
       "0       ₹ 3.5 Cr        7.2  48.5         1.4    0.60          44.80   \n",
       "1      ₹ 9.04 Cr        NaN   NaN         NaN     NaN            NaN   \n",
       "2      ₹ 1.75 Cr        5.9  24.8         1.6    0.45          44.25   \n",
       "3      ₹ 0.89 Cr        NaN   NaN         NaN     NaN            NaN   \n",
       "4      ₹ 2.25 Cr        5.2  28.5         1.6    0.45          45.75   \n",
       "\n",
       "   day_total             budget verdict india_screens overseas_screens  \\\n",
       "0      102.5  ₹ 450 Cr * Approx    Flop   India: 7000   Overseas: 3000   \n",
       "1        NaN  ₹ 450 Cr * Approx    Flop   India: 7000   Overseas: 3000   \n",
       "2       77.0  ₹ 450 Cr * Approx    Flop   India: 7000   Overseas: 3000   \n",
       "3        NaN  ₹ 450 Cr * Approx    Flop   India: 7000   Overseas: 3000   \n",
       "4       81.5  ₹ 450 Cr * Approx    Flop   India: 7000   Overseas: 3000   \n",
       "\n",
       "        worldwide_screens    release_date                       primary_key  \n",
       "0  Worldwide total: 10000  16th June 2023    Adipurush | Day 1 [1st Friday]  \n",
       "1  Worldwide total: 10000  16th June 2023          Adipurush | Week 1 Share  \n",
       "2  Worldwide total: 10000  16th June 2023  Adipurush | Day 2 [1st Saturday]  \n",
       "3  Worldwide total: 10000  16th June 2023          Adipurush | Week 2 Share  \n",
       "4  Worldwide total: 10000  16th June 2023    Adipurush | Day 3 [1st Sunday]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Master_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc18e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cleaning process on 737 rows...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected value of kwarg 'errors' to be one of ['raise', 'ignore']. Supplied value is 'coerce'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m SCREEN_COLS:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;66;03m# Extracts digits only from strings like \"India: 7000\" or \"Worldwide total: 10000\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m         df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoerce\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m         df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Found\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan}) \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Clean release_date (Source format: \"16th June 2023\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:6665\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6660\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6661\u001b[0m     ]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6664\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6665\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6666\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:449\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    447\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    782\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    788\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:222\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m errors_legal_values:\n\u001b[0;32m    218\u001b[0m     invalid_arg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected value of kwarg \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(errors_legal_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Supplied value is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(invalid_arg)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    225\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected value of kwarg 'errors' to be one of ['raise', 'ignore']. Supplied value is 'coerce'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. LOAD DATA\n",
    "# -------------------------------------------------------------------\n",
    "# Assuming 'Master_cleaned.csv' contains the raw, combined data (including currency/symbols)\n",
    "df = pd.read_csv('Master_cleaned.csv')\n",
    "\n",
    "print(f\"Starting cleaning process on {len(df)} rows...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. CORE CLEANING FUNCTIONS\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def clean_collection_value(series):\n",
    "    \"\"\"Removes currency, crore markers, percentage signs, and handles text junk.\"\"\"\n",
    "    if not pd.api.types.is_numeric_dtype(series):\n",
    "        series = series.astype(str)\n",
    "        # Remove currency symbols (₹, Cr, * Approx)\n",
    "        series = series.str.replace('₹', '', regex=False)\n",
    "        series = series.str.replace(r' Cr\\*? Approx', '', regex=True)\n",
    "        series = series.str.replace(' Cr', '', regex=False)\n",
    "        series = series.str.replace('%', '', regex=False)\n",
    "        series = series.str.replace('* Approx', '', regex=False) # For budget column\n",
    "        \n",
    "        # Replace explicit missing indicators with NaN\n",
    "        series = series.replace({\n",
    "            '-': np.nan, \n",
    "            'Not Found': np.nan, \n",
    "            'nan': np.nan,\n",
    "            '': np.nan\n",
    "        })\n",
    "        \n",
    "        # Complex data removal (e.g., [Te: 66.75 Cr;...])\n",
    "        # We assume the main number (e.g., '13.7' in '13.7,₹ 3.5 Cr') is in india_net.\n",
    "        # However, looking at the source data [1], some columns like 'india_net' already hold cleaned floats (13.7) while others contain junk.\n",
    "        # To handle columns where collections might contain extra language breakdowns (like the old raw scrape output), we rely on forcing numeric conversion.\n",
    "\n",
    "    # Attempt float conversion, coercing errors (junk data) to NaN\n",
    "    return pd.to_numeric(series, errors='coerce')\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. APPLY NUMERICAL CLEANING\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Columns that should contain numeric collection or percentage values, potentially mixed with text/symbols:\n",
    "COLLECTION_COLS = [\n",
    "    'india_net', 'change_percent', 'karnataka', 'aptg', 'tamil_nadu', \n",
    "    'kerala', 'rest_of_india', 'day_total', 'budget'\n",
    "]\n",
    "# Ensure these columns exist before attempting to clean them\n",
    "COLLECTION_COLS = [col for col in COLLECTION_COLS if col in df.columns]\n",
    "\n",
    "\n",
    "for col in COLLECTION_COLS:\n",
    "    # Overwrite the original column with the cleaned numeric values\n",
    "    df[col] = clean_collection_value(df[col])\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. CLEANING NON-COLLECTION COLUMNS (Screens, Dates)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Clean screens data (Extract the number from \"India: 7000\")\n",
    "SCREEN_COLS = ['india_screens', 'overseas_screens', 'worldwide_screens']\n",
    "for col in SCREEN_COLS:\n",
    "    if col in df.columns:\n",
    "        # Extracts digits only from strings like \"India: 7000\" or \"Worldwide total: 10000\"\n",
    "        df[col] = df[col].astype(str).str.extract(r'(\\d+)').astype(float, errors='coerce')\n",
    "        df[col] = df[col].replace({'Not Found': np.nan}) # Handle missing values\n",
    "\n",
    "\n",
    "# Clean release_date (Source format: \"16th June 2023\")\n",
    "if 'release_date' in df.columns:\n",
    "    # Extract the full date string, which is necessary for proper date parsing later\n",
    "    # Example: '16th June 2023' [1]\n",
    "    df['release_date'] = df['release_date'].astype(str).str.extract(r'(\\d{1,2}\\w{2} \\w+ \\d{4})')\n",
    "    df['release_date'] = df['release_date'].fillna(df['release_date'].str.extract(r'(\\d{1,2}\\w+ \\w+ \\d{4})')).fillna(np.nan) # Catch variations\n",
    "    # Convert to datetime object (better for analysis)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "\n",
    "# Clean movie column (Remove external junk often appended in titles)\n",
    "if 'movie' in df.columns:\n",
    "    df['movie'] = df['movie'].astype(str).str.split(' Box Office').str.str.strip()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. KEEP IDENTIFIERS CLEAN\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Ensure categorical/text/identifier columns remain as strings/objects:\n",
    "# 'movie_id' (should be int), 'hero', 'movie', 'day', 'verdict', 'primary_key'\n",
    "if 'movie_id' in df.columns:\n",
    "    df['movie_id'] = pd.to_numeric(df['movie_id'], errors='coerce').astype('Int64', errors='ignore') # Ensure correct integer type\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. SAVE CLEANED DATA\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "df.to_csv('Master_cleaned_V2.csv', index=False)\n",
    "df.to_excel('Master_cleaned_V2.xlsx', index=False)\n",
    "print(\"\\nCleaned and saved to 'Master_cleaned_V2.csv' and 'Master_cleaned_V2.xlsx'!\")\n",
    "print(df[COLLECTION_COLS + ['release_date', 'hero', 'india_screens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbfb5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed and saved as Master_final_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load file\n",
    "df = pd.read_csv(\"Master_cleaned.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Strip spaces in all string columns\n",
    "# -----------------------------\n",
    "df = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Remove unwanted characters inside numeric columns\n",
    "# Example: \"1 234\", \"12,300\", \"₹ 50000\", \"10.0%\", \"abc123\"\n",
    "# -----------------------------\n",
    "def clean_numeric(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    x = str(x)\n",
    "    x = x.replace(\" \", \"\")       # remove spaces\n",
    "    x = re.sub(r\"[^0-9.\\-]\", \"\", x)  # keep only numbers, dot, minus\n",
    "    return x if x != \"\" else np.nan\n",
    "\n",
    "for col in df.columns:\n",
    "    # detect possible numeric columns\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Convert cleaned numeric columns to proper dtype\n",
    "# -----------------------------\n",
    "for col in df.columns:\n",
    "    # try converting to float\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Replace empty strings with NaN\n",
    "# -----------------------------\n",
    "df.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Optional: drop duplicates\n",
    "# -----------------------------\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. OPTIONAL: Fill missing values (customizable)\n",
    "# -----------------------------\n",
    "# df.fillna({\"column_name\": 0}, inplace=True)\n",
    "\n",
    "# Save final cleaned file\n",
    "df.to_csv(\"Master_final_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning completed and saved as Master_final_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e959f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 737 rows, 48 movies\n",
      "\n",
      "SUPER CLEANING DONE!\n",
      "Saved → Master_super_cleaned.csv & .xlsx\n",
      "\n",
      "First 10 rows:\n",
      "   movie_id     hero      movie                    day  india_net\n",
      "0         1  Prabhas  Adipurush     Day 1 [1st Friday]      13.70\n",
      "1         1  Prabhas  Adipurush           Week 1 Share      34.00\n",
      "2         1  Prabhas  Adipurush   Day 2 [1st Saturday]       7.78\n",
      "3         1  Prabhas  Adipurush           Week 2 Share       2.31\n",
      "4         1  Prabhas  Adipurush     Day 3 [1st Sunday]       8.15\n",
      "5         1  Prabhas  Adipurush     Day 4 [1st Monday]       2.15\n",
      "6         1  Prabhas  Adipurush    Day 5 [1st Tuesday]       1.22\n",
      "7         1  Prabhas  Adipurush  Day 6 [1st Wednesday]       0.62\n",
      "8         1  Prabhas  Adipurush   Day 7 [1st Thursday]       0.38\n",
      "9         1  Prabhas  Adipurush     Day 8 [2nd Friday]       0.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file\n",
    "df = pd.read_csv(\"Master_cleaned.csv\")\n",
    "print(f\"Loaded {len(df)} rows, {df['movie'].nunique()} movies\")\n",
    "\n",
    "# 1. Clean numeric columns (remove ₹, Cr, %, extract numbers)\n",
    "num_cols = ['india_net', 'day_total', 'karnataka', 'aptg', 'tamil_nadu', 'kerala', 'rest_of_india']\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].astype(str).str.extract(r'([\\d\\.]+)').astype(float).fillna(0)  # Fill missing with 0\n",
    "\n",
    "# 2. Clean change_percent (remove %, extract number)\n",
    "df['change_percent'] = df['change_percent'].astype(str).str.extract(r'([\\d\\.]+)').astype(float).fillna(0)\n",
    "\n",
    "# 3. Clean budget (extract number)\n",
    "df['budget'] = df['budget'].astype(str).str.extract(r'([\\d\\.]+)').astype(float).fillna(0)\n",
    "\n",
    "# 4. Clean verdict (replace \"Not Found\" with \"Unknown\")\n",
    "df['verdict'] = df['verdict'].replace(\"Not Found\", \"Unknown\")\n",
    "\n",
    "# 5. Clean release_date (extract date only if junk)\n",
    "df['release_date'] = df['release_date'].astype(str).str.extract(r'(\\d{1,2}\\w{2} \\w+ \\d{4})')\n",
    "\n",
    "# 6. Reorder columns (same as yours)\n",
    "final_cols = df.columns.tolist()\n",
    "df = df[final_cols]\n",
    "\n",
    "# 7. Save super clean versions\n",
    "df.to_csv(\"Master_super_cleaned.csv\", index=False)\n",
    "df.to_excel(\"Master_super_cleaned.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nSUPER CLEANING DONE!\")\n",
    "print(\"Saved → Master_super_cleaned.csv & .xlsx\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df[['movie_id', 'hero', 'movie', 'day', 'india_net']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58bf3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>hero</th>\n",
       "      <th>movie</th>\n",
       "      <th>day</th>\n",
       "      <th>india_net</th>\n",
       "      <th>change_percent</th>\n",
       "      <th>karnataka</th>\n",
       "      <th>aptg</th>\n",
       "      <th>tamil_nadu</th>\n",
       "      <th>kerala</th>\n",
       "      <th>rest_of_india</th>\n",
       "      <th>day_total</th>\n",
       "      <th>budget</th>\n",
       "      <th>verdict</th>\n",
       "      <th>india_screens</th>\n",
       "      <th>overseas_screens</th>\n",
       "      <th>worldwide_screens</th>\n",
       "      <th>release_date</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 1 [1st Friday]</td>\n",
       "      <td>13.70</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7.2</td>\n",
       "      <td>48.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>44.80</td>\n",
       "      <td>102.5</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 1 [1st Friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Week 1 Share</td>\n",
       "      <td>34.00</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Week 1 Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 2 [1st Saturday]</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>44.25</td>\n",
       "      <td>77.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 2 [1st Saturday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Week 2 Share</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Week 2 Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Prabhas</td>\n",
       "      <td>Adipurush</td>\n",
       "      <td>Day 3 [1st Sunday]</td>\n",
       "      <td>8.15</td>\n",
       "      <td>2.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>45.75</td>\n",
       "      <td>81.5</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Flop</td>\n",
       "      <td>India: 7000</td>\n",
       "      <td>Overseas: 3000</td>\n",
       "      <td>Worldwide total: 10000</td>\n",
       "      <td>16th June 2023</td>\n",
       "      <td>Adipurush | Day 3 [1st Sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id     hero      movie                   day  india_net  \\\n",
       "0         1  Prabhas  Adipurush    Day 1 [1st Friday]      13.70   \n",
       "1         1  Prabhas  Adipurush          Week 1 Share      34.00   \n",
       "2         1  Prabhas  Adipurush  Day 2 [1st Saturday]       7.78   \n",
       "3         1  Prabhas  Adipurush          Week 2 Share       2.31   \n",
       "4         1  Prabhas  Adipurush    Day 3 [1st Sunday]       8.15   \n",
       "\n",
       "   change_percent  karnataka  aptg  tamil_nadu  kerala  rest_of_india  \\\n",
       "0            3.50        7.2  48.5         1.4    0.60          44.80   \n",
       "1            9.04        0.0   0.0         0.0    0.00           0.00   \n",
       "2            1.75        5.9  24.8         1.6    0.45          44.25   \n",
       "3            0.89        0.0   0.0         0.0    0.00           0.00   \n",
       "4            2.25        5.2  28.5         1.6    0.45          45.75   \n",
       "\n",
       "   day_total  budget verdict india_screens overseas_screens  \\\n",
       "0      102.5   450.0    Flop   India: 7000   Overseas: 3000   \n",
       "1        0.0   450.0    Flop   India: 7000   Overseas: 3000   \n",
       "2       77.0   450.0    Flop   India: 7000   Overseas: 3000   \n",
       "3        0.0   450.0    Flop   India: 7000   Overseas: 3000   \n",
       "4       81.5   450.0    Flop   India: 7000   Overseas: 3000   \n",
       "\n",
       "        worldwide_screens    release_date                       primary_key  \n",
       "0  Worldwide total: 10000  16th June 2023    Adipurush | Day 1 [1st Friday]  \n",
       "1  Worldwide total: 10000  16th June 2023          Adipurush | Week 1 Share  \n",
       "2  Worldwide total: 10000  16th June 2023  Adipurush | Day 2 [1st Saturday]  \n",
       "3  Worldwide total: 10000  16th June 2023          Adipurush | Week 2 Share  \n",
       "4  Worldwide total: 10000  16th June 2023    Adipurush | Day 3 [1st Sunday]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b860d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Rows split successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Master_super_cleaned.csv\")\n",
    "\n",
    "# Split hero column into multiple rows\n",
    "df[\"hero\"] = df[\"hero\"].str.split(\"/\")     # Convert \"Jr NTR/Ram Charan\" → [\"Jr NTR\", \"Ram Charan\"]\n",
    "df = df.explode(\"hero\")                    # Creates 2 rows from 1\n",
    "\n",
    "# Remove spaces\n",
    "df[\"hero\"] = df[\"hero\"].str.strip()\n",
    "\n",
    "df.to_csv(\"Master_super_cleaned_hero_fixed.csv\", index=False)\n",
    "\n",
    "print(\"Done! Rows split successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395b0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
